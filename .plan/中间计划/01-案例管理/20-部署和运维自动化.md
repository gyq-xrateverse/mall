# 20-部署和运维自动化

## 任务概述
为案例管理系统建立完整的自动化部署和运维体系，包括容器化部署、CI/CD流水线、监控告警和备份恢复机制。

## 前置条件
- 所有开发任务已完成
- 服务器环境已准备
- Docker和相关工具已安装
- Git仓库已配置

## 实施步骤

### 1. Docker容器化

#### 后端服务Dockerfile
**文件路径：** `mall/Dockerfile`

```dockerfile
# 多阶段构建
FROM openjdk:8-jdk-alpine AS builder

WORKDIR /app

# 复制Maven配置
COPY pom.xml .
COPY mall-mbg/pom.xml mall-mbg/
COPY mall-admin/pom.xml mall-admin/
COPY mall-portal/pom.xml mall-portal/
COPY mall-common/pom.xml mall-common/
COPY mall-security/pom.xml mall-security/

# 下载依赖
RUN apk add --no-cache maven
RUN mvn dependency:go-offline -B

# 复制源码并编译
COPY . .
RUN mvn clean package -DskipTests

# 运行时镜像
FROM openjdk:8-jre-alpine

RUN apk add --no-cache \
    bash \
    curl \
    tzdata \
    && cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    && echo "Asia/Shanghai" > /etc/timezone

WORKDIR /app

# 复制编译后的jar文件
COPY --from=builder /app/mall-admin/target/mall-admin-*.jar app.jar

# 创建非root用户
RUN addgroup -g 1001 -S appgroup && \
    adduser -u 1001 -S appuser -G appgroup

# 设置JVM参数
ENV JAVA_OPTS="-server -Xms512m -Xmx1024m -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:+UseGCOverheadLimit -XX:+ExplicitGCInvokesConcurrent -Djava.security.egd=file:/dev/./urandom"

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:8080/actuator/health || exit 1

USER appuser

EXPOSE 8080

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

#### 前端Dockerfile
**文件路径：** `mall-admin-web/Dockerfile`

```dockerfile
# 构建阶段
FROM node:16-alpine AS builder

WORKDIR /app

# 复制package文件
COPY package*.json ./

# 安装依赖
RUN npm ci --only=production

# 复制源码
COPY . .

# 构建应用
RUN npm run build:prod

# 运行阶段
FROM nginx:1.21-alpine

# 复制nginx配置
COPY nginx.conf /etc/nginx/nginx.conf

# 复制构建结果
COPY --from=builder /app/dist /usr/share/nginx/html

# 创建日志目录
RUN mkdir -p /var/log/nginx

# 设置权限
RUN chown -R nginx:nginx /usr/share/nginx/html && \
    chown -R nginx:nginx /var/cache/nginx && \
    chown -R nginx:nginx /var/log/nginx

# 健康检查
HEALTHCHECK --interval=30s --timeout=5s --start-period=30s --retries=3 \
  CMD curl -f http://localhost || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

#### Nginx配置
**文件路径：** `mall-admin-web/nginx.conf`

```nginx
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # 日志格式
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    '$request_time $upstream_response_time';
    
    access_log /var/log/nginx/access.log main;
    
    # 基本设置
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    # Gzip压缩
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # 安全头
    add_header X-Frame-Options SAMEORIGIN always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    
    # 上游服务器
    upstream backend {
        server mall-admin:8080 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }
    
    server {
        listen 80;
        server_name _;
        root /usr/share/nginx/html;
        index index.html;
        
        # 静态资源缓存
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            try_files $uri =404;
        }
        
        # API代理
        location /api/ {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            proxy_buffering on;
            proxy_buffer_size 8k;
            proxy_buffers 8 8k;
        }
        
        # SPA路由支持
        location / {
            try_files $uri $uri/ /index.html;
        }
        
        # 健康检查
        location /health {
            return 200 "ok";
            add_header Content-Type text/plain;
        }
        
        # 错误页面
        error_page 404 /index.html;
        error_page 500 502 503 504 /50x.html;
        
        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }
}
```

### 2. Docker Compose配置

#### 完整服务编排
**文件路径：** `docker-compose.yml`

```yaml
version: '3.8'

services:
  # MySQL数据库
  mysql:
    image: mysql:8.0
    container_name: mall-mysql
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-root123}
      MYSQL_DATABASE: mall
      MYSQL_USER: mall
      MYSQL_PASSWORD: ${MYSQL_PASSWORD:-mall123}
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./docker/mysql/conf:/etc/mysql/conf.d
      - ./docker/mysql/init:/docker-entrypoint-initdb.d
    command: 
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
      - --max_connections=1000
    networks:
      - mall-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10

  # Redis缓存
  redis:
    image: redis:7-alpine
    container_name: mall-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./docker/redis/redis.conf:/etc/redis/redis.conf
    command: redis-server /etc/redis/redis.conf
    networks:
      - mall-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # MinIO对象存储
  minio:
    image: minio/minio:latest
    container_name: mall-minio
    restart: unless-stopped
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY:-minioadmin123}
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      - mall-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # 后端应用
  mall-admin:
    build: ./mall
    container_name: mall-admin
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-prod}
      DB_HOST: mysql
      DB_PORT: 3306
      DB_NAME: mall
      DB_USER: mall
      DB_PASSWORD: ${MYSQL_PASSWORD:-mall123}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY:-minioadmin123}
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    networks:
      - mall-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - ./logs:/app/logs

  # 管理前端
  mall-admin-web:
    build: ./mall-admin-web
    container_name: mall-admin-web
    restart: unless-stopped
    ports:
      - "80:80"
    depends_on:
      - mall-admin
    networks:
      - mall-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  # 用户前端
  beilv-agent-web:
    build: ./beilv-agent-web
    container_name: beilv-agent-web
    restart: unless-stopped
    ports:
      - "3000:80"
    depends_on:
      - mall-admin
    networks:
      - mall-network

  # Prometheus监控
  prometheus:
    image: prom/prometheus:latest
    container_name: mall-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - mall-network

  # Grafana可视化
  grafana:
    image: grafana/grafana:latest
    container_name: mall-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin123}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - mall-network

volumes:
  mysql_data:
  redis_data:
  minio_data:
  prometheus_data:
  grafana_data:

networks:
  mall-network:
    driver: bridge
```

### 3. CI/CD流水线

#### GitHub Actions工作流
**文件路径：** `.github/workflows/ci-cd.yml`

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  DOCKER_REGISTRY: your-registry.com
  PROJECT_NAME: mall-case-system

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: root123
          MYSQL_DATABASE: mall_test
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3
      
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        java-version: '8'
        distribution: 'temurin'

    - name: Cache Maven dependencies
      uses: actions/cache@v3
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        restore-keys: ${{ runner.os }}-m2

    - name: Run backend tests
      run: |
        cd mall
        mvn clean test -Dspring.profiles.active=test

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '16'
        cache: 'npm'
        cache-dependency-path: |
          mall-admin-web/package-lock.json
          beilv-agent-web/package-lock.json

    - name: Install frontend dependencies and run tests
      run: |
        cd mall-admin-web
        npm ci
        npm run test:unit
        
        cd ../beilv-agent-web
        npm ci
        npm run test

    - name: Code quality check
      run: |
        cd mall
        mvn sonar:sonar \
          -Dsonar.projectKey=${{ env.PROJECT_NAME }} \
          -Dsonar.host.url=${{ secrets.SONAR_HOST_URL }} \
          -Dsonar.login=${{ secrets.SONAR_TOKEN }}

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Login to Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.DOCKER_REGISTRY }}
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Build and push backend image
      uses: docker/build-push-action@v4
      with:
        context: ./mall
        push: true
        tags: |
          ${{ env.DOCKER_REGISTRY }}/${{ env.PROJECT_NAME }}-backend:latest
          ${{ env.DOCKER_REGISTRY }}/${{ env.PROJECT_NAME }}-backend:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build and push admin frontend image
      uses: docker/build-push-action@v4
      with:
        context: ./mall-admin-web
        push: true
        tags: |
          ${{ env.DOCKER_REGISTRY }}/${{ env.PROJECT_NAME }}-admin-web:latest
          ${{ env.DOCKER_REGISTRY }}/${{ env.PROJECT_NAME }}-admin-web:${{ github.sha }}

    - name: Build and push user frontend image
      uses: docker/build-push-action@v4
      with:
        context: ./beilv-agent-web
        push: true
        tags: |
          ${{ env.DOCKER_REGISTRY }}/${{ env.PROJECT_NAME }}-user-web:latest
          ${{ env.DOCKER_REGISTRY }}/${{ env.PROJECT_NAME }}-user-web:${{ github.sha }}

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Deploy to production
      uses: appleboy/ssh-action@v0.1.5
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USER }}
        key: ${{ secrets.PROD_SSH_KEY }}
        script: |
          cd /opt/mall-case-system
          
          # 备份当前版本
          docker-compose down
          cp docker-compose.yml docker-compose.yml.backup.$(date +%Y%m%d_%H%M%S)
          
          # 拉取最新代码
          git pull origin main
          
          # 更新镜像
          docker-compose pull
          
          # 启动服务
          docker-compose up -d
          
          # 健康检查
          sleep 30
          docker-compose ps
          
          # 清理旧镜像
          docker image prune -f

    - name: Notify deployment
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        message: |
          Deployment ${{ job.status }}!
          Project: ${{ env.PROJECT_NAME }}
          Commit: ${{ github.sha }}
          Branch: ${{ github.ref }}
```

### 4. 监控配置

#### Prometheus配置
**文件路径：** `docker/prometheus/prometheus.yml`

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # Mall后端服务
  - job_name: 'mall-admin'
    static_configs:
      - targets: ['mall-admin:8080']
    metrics_path: '/actuator/prometheus'
    scrape_interval: 15s

  # MySQL监控
  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']

  # Redis监控
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginx监控
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']

  # Node监控
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

  # 容器监控
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
```

#### 告警规则
**文件路径：** `docker/prometheus/rules/alerts.yml`

```yaml
groups:
- name: mall-alerts
  rules:
  # 服务可用性告警
  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Service {{ $labels.job }} is down"
      description: "{{ $labels.job }} has been down for more than 1 minute."

  # CPU使用率告警
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage on {{ $labels.instance }}"
      description: "CPU usage is above 80% for more than 5 minutes."

  # 内存使用率告警
  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 90
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"
      description: "Memory usage is above 90% for more than 5 minutes."

  # 磁盘空间告警
  - alert: DiskSpaceLow
    expr: node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} * 100 < 10
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Low disk space on {{ $labels.instance }}"
      description: "Disk space is below 10% on root filesystem."

  # API响应时间告警
  - alert: HighAPIResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High API response time"
      description: "95th percentile of API response time is above 2 seconds."

  # 错误率告警
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100 > 5
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate"
      description: "HTTP 5xx error rate is above 5% for more than 5 minutes."

  # 数据库连接告警
  - alert: DatabaseConnectionHigh
    expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High database connections"
      description: "Database connection usage is above 80%."

  # Redis内存使用告警
  - alert: RedisMemoryHigh
    expr: redis_memory_used_bytes / redis_config_maxmemory * 100 > 90
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High Redis memory usage"
      description: "Redis memory usage is above 90%."
```

### 5. 备份和恢复脚本

#### 自动备份脚本
**文件路径：** `scripts/backup.sh`

```bash
#!/bin/bash

set -e

# 配置
BACKUP_DIR="/opt/backups/mall-case-system"
MYSQL_CONTAINER="mall-mysql"
REDIS_CONTAINER="mall-redis"
MINIO_CONTAINER="mall-minio"
RETENTION_DAYS=30

# 创建备份目录
mkdir -p ${BACKUP_DIR}

# 获取当前时间戳
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

echo "Starting backup at $(date)"

# 1. MySQL数据备份
echo "Backing up MySQL database..."
docker exec ${MYSQL_CONTAINER} mysqldump \
    --single-transaction \
    --routines \
    --triggers \
    --all-databases \
    -uroot -p${MYSQL_ROOT_PASSWORD} \
    | gzip > ${BACKUP_DIR}/mysql_${TIMESTAMP}.sql.gz

# 2. Redis数据备份
echo "Backing up Redis data..."
docker exec ${REDIS_CONTAINER} redis-cli BGSAVE
sleep 5
docker cp ${REDIS_CONTAINER}:/data/dump.rdb ${BACKUP_DIR}/redis_${TIMESTAMP}.rdb

# 3. MinIO数据备份
echo "Backing up MinIO data..."
docker run --rm \
    --volumes-from ${MINIO_CONTAINER} \
    -v ${BACKUP_DIR}:/backup \
    alpine \
    tar czf /backup/minio_${TIMESTAMP}.tar.gz -C /data .

# 4. 应用配置备份
echo "Backing up application configs..."
tar czf ${BACKUP_DIR}/configs_${TIMESTAMP}.tar.gz \
    docker-compose.yml \
    .env \
    docker/

# 5. 清理过期备份
echo "Cleaning up old backups..."
find ${BACKUP_DIR} -name "*.gz" -mtime +${RETENTION_DAYS} -delete
find ${BACKUP_DIR} -name "*.rdb" -mtime +${RETENTION_DAYS} -delete

# 6. 备份验证
echo "Verifying backups..."
if [ -f "${BACKUP_DIR}/mysql_${TIMESTAMP}.sql.gz" ] && 
   [ -f "${BACKUP_DIR}/redis_${TIMESTAMP}.rdb" ] && 
   [ -f "${BACKUP_DIR}/minio_${TIMESTAMP}.tar.gz" ] && 
   [ -f "${BACKUP_DIR}/configs_${TIMESTAMP}.tar.gz" ]; then
    echo "✅ All backups completed successfully"
    
    # 发送通知
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"Mall Case System backup completed successfully at $(date)\"}" \
        ${SLACK_WEBHOOK_URL}
else
    echo "❌ Backup failed"
    exit 1
fi

echo "Backup completed at $(date)"
```

#### 恢复脚本
**文件路径：** `scripts/restore.sh`

```bash
#!/bin/bash

set -e

# 配置
BACKUP_DIR="/opt/backups/mall-case-system"
MYSQL_CONTAINER="mall-mysql"
REDIS_CONTAINER="mall-redis"
MINIO_CONTAINER="mall-minio"

# 检查参数
if [ $# -ne 1 ]; then
    echo "Usage: $0 <backup_timestamp>"
    echo "Example: $0 20240101_120000"
    exit 1
fi

TIMESTAMP=$1

echo "Starting restore from backup ${TIMESTAMP} at $(date)"

# 验证备份文件存在
if [ ! -f "${BACKUP_DIR}/mysql_${TIMESTAMP}.sql.gz" ] || 
   [ ! -f "${BACKUP_DIR}/redis_${TIMESTAMP}.rdb" ] || 
   [ ! -f "${BACKUP_DIR}/minio_${TIMESTAMP}.tar.gz" ]; then
    echo "❌ Backup files not found for timestamp ${TIMESTAMP}"
    exit 1
fi

# 确认操作
read -p "This will overwrite current data. Are you sure? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Restore cancelled"
    exit 1
fi

# 停止服务
echo "Stopping services..."
docker-compose down

# 1. 恢复MySQL数据
echo "Restoring MySQL database..."
docker-compose up -d mysql
sleep 30

gunzip -c ${BACKUP_DIR}/mysql_${TIMESTAMP}.sql.gz | \
    docker exec -i ${MYSQL_CONTAINER} mysql -uroot -p${MYSQL_ROOT_PASSWORD}

# 2. 恢复Redis数据
echo "Restoring Redis data..."
docker-compose stop redis
docker cp ${BACKUP_DIR}/redis_${TIMESTAMP}.rdb ${REDIS_CONTAINER}:/data/dump.rdb
docker-compose start redis

# 3. 恢复MinIO数据
echo "Restoring MinIO data..."
docker-compose stop minio
docker run --rm \
    --volumes-from ${MINIO_CONTAINER} \
    -v ${BACKUP_DIR}:/backup \
    alpine \
    sh -c "cd /data && tar xzf /backup/minio_${TIMESTAMP}.tar.gz"
docker-compose start minio

# 4. 启动所有服务
echo "Starting all services..."
docker-compose up -d

# 5. 健康检查
echo "Performing health checks..."
sleep 60

# 检查服务状态
services=("mysql" "redis" "minio" "mall-admin" "mall-admin-web")
for service in "${services[@]}"; do
    if docker-compose ps ${service} | grep -q "Up"; then
        echo "✅ ${service} is running"
    else
        echo "❌ ${service} is not running"
    fi
done

echo "Restore completed at $(date)"
```

## 验证步骤
1. 测试Docker镜像构建和运行
2. 验证CI/CD流水线执行
3. 检查监控告警配置
4. 测试备份和恢复流程
5. 验证服务的健康检查

## 输出物
- Docker容器化配置
- CI/CD流水线配置
- 监控告警规则
- 自动化备份恢复脚本
- 部署文档和运维手册

## 注意事项
1. 确保敏感信息使用环境变量
2. 定期测试备份恢复流程
3. 监控资源使用情况
4. 保持镜像和依赖的安全更新

## 后续任务
- 下一步：21-项目文档和交付.md