# AI视频生成工作流系统详细需求

## 项目背景

基于现有的mall电商系统，开发一个AI视频生成工作流系统，通过智能分析用户提示词和上传的图片，动态生成完整的视频制作工作流，并自动执行生成最终的短视频内容。

## 项目架构

### 现有项目结构
- **管理后端前端项目**：`/mnt/d/software/beilv-agent/mall/mall-admin-web`
- **管理后端后端项目**：`/mnt/d/software/beilv-agent/mall/mall/mall-admin`
- **用户端前端项目**：`/mnt/d/software/beilv-agent/mall/beilv-agent-web`
- **用户端后端项目**：`/mnt/d/software/beilv-agent/mall/mall/mall-portal`
- **智能体Python后端项目**：`/mnt/d/software/beilv-agent/mall/beilv-agent` (新建FastAPI项目)

### 技术栈
- **前端**：React + TypeScript + Ant Design
- **Java后端**：Spring Boot + MyBatis + MySQL
- **Python AI服务**：FastAPI + LangChain + Celery
- **数据库**：MySQL (共享)
- **文件存储**：MinIO/阿里云OSS
- **实时通信**：WebSocket

## 核心功能需求

### 1. AI工具注册系统

Python后端通过LangChain注册支持的工具，每个工具函数都需要有唯一且固定的UUID，便于数据库记录后，后端程序通过UUID定位对应的函数。

#### 1.1 工具列表 (10个AI工具)
1. **文生图** (第三方API) - UUID: `tool-text2img-001`
2. **图生图** (第三方API) - UUID: `tool-img2img-002`
3. **图生视频** (第三方API) - UUID: `tool-img2video-003`
4. **文生视频** (第三方API) - UUID: `tool-text2video-004`
5. **背景音乐生成** (第三方API) - UUID: `tool-music-gen-005`
6. **文案转语音** (第三方API) - UUID: `tool-text2speech-008`
7. **语音生成字幕** (第三方API) - UUID: `tool-speech2sub-009`
8. **视频合并** (本地接口) - UUID: `tool-video-merge-010`
9. **音视频合并** (本地接口) - UUID: `tool-av-merge-011`
10. **字幕视频合并** (本地接口) - UUID: `tool-sub-merge-012`

**说明**：图片理解、生成图片提示词、生成视频提示词、口播文案生成功能已整合到工作流生成阶段，由LLM在分析用户输入时一次性完成。

#### 1.2 AI模型适配器架构设计

为了支持后续切换不同的AI模型提供商（如豆包、通义千问、文心一言等），采用适配器模式设计AI模型接入层。

##### 1.2.1 混合平台适配器架构
```text
AI工具层 (tool-text2img-001, tool-img2video-003...)
       ↓
智能适配器选择器 (SmartAdapterSelector)
       ↓
AI模型适配器层 (DouBao, TongYi, WenXin, OpenAI...)
       ↓
AI模型提供商层 (各平台API调用)
```

**核心理念**：各取所长，混合使用不同AI平台的优势能力
- 📸 **图像生成** - 通义千问 (图片质量佳)
- 🎬 **视频生成** - 豆包 (视频效果好)
- 🎵 **音频处理** - 文心一言 (音频技术强)
- 💰 **成本控制** - 根据价格选择最优平台
- 🌍 **地域适配** - 不同地区使用不同平台

##### 1.2.2 按工具功能的适配器接口设计
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

@dataclass
class AIModelResult:
    """AI模型调用结果"""
    success: bool
    data: Optional[Dict[str, Any]] = None
    files: Optional[List[str]] = None  # 生成的文件URL列表
    error_message: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None  # 模型返回的元数据

# ===== 按工具功能分别定义适配器基类 =====

class BaseT2IAdapter(ABC):
    """文生图适配器基类"""

    @abstractmethod
    def text_to_image(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """文生图接口"""
        pass

class BaseI2IAdapter(ABC):
    """图生图适配器基类"""

    @abstractmethod
    def image_to_image(self, prompt: str, source_image: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """图生图接口"""
        pass

class BaseI2VAdapter(ABC):
    """图生视频适配器基类"""

    @abstractmethod
    def image_to_video(self, prompt: str, source_image: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """图生视频接口"""
        pass

class BaseT2VAdapter(ABC):
    """文生视频适配器基类"""

    @abstractmethod
    def text_to_video(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """文生视频接口"""
        pass

class BaseMusicGenAdapter(ABC):
    """音乐生成适配器基类"""

    @abstractmethod
    def generate_music(self, prompt: str, **kwargs) -> AIModelResult:
        """音乐生成接口"""
        pass

class BaseTTS_Adapter(ABC):
    """文本转语音适配器基类"""

    @abstractmethod
    def text_to_speech(self, text: str, voice_id: str, **kwargs) -> AIModelResult:
        """文本转语音接口"""
        pass

class BaseASR_Adapter(ABC):
    """语音转字幕适配器基类"""

    @abstractmethod
    def speech_to_subtitle(self, audio_url: str, language: str, **kwargs) -> AIModelResult:
        """语音转字幕接口"""
        pass

# ===== 工具适配器工厂类 =====

class ToolAdapterFactory:
    """工具适配器工厂类"""

    _adapters = {
        "text_to_image": {},      # 存储文生图适配器
        "image_to_image": {},     # 存储图生图适配器
        "image_to_video": {},     # 存储图生视频适配器
        "text_to_video": {},      # 存储文生视频适配器
        "generate_music": {},     # 存储音乐生成适配器
        "text_to_speech": {},     # 存储语音合成适配器
        "speech_to_subtitle": {}  # 存储语音识别适配器
    }

    @classmethod
    def register_adapter(cls, tool_type: str, platform: str, adapter_class):
        """注册工具适配器"""
        if tool_type not in cls._adapters:
            raise ValueError(f"Unknown tool type: {tool_type}")
        cls._adapters[tool_type][platform] = adapter_class

    @classmethod
    def create_adapter(cls, tool_type: str, platform: str, config: Dict[str, Any]):
        """创建工具适配器实例"""
        if tool_type not in cls._adapters:
            raise ValueError(f"Unknown tool type: {tool_type}")

        if platform not in cls._adapters[tool_type]:
            raise ValueError(f"Platform {platform} not available for {tool_type}")

        adapter_class = cls._adapters[tool_type][platform]
        return adapter_class(config)

    @classmethod
    def list_platforms(cls, tool_type: str) -> List[str]:
        """列出指定工具类型的可用平台"""
        if tool_type not in cls._adapters:
            return []
        return list(cls._adapters[tool_type].keys())

    @classmethod
    def list_all_capabilities(cls) -> Dict[str, List[str]]:
        """列出所有工具类型及其可用平台"""
        return {
            tool_type: list(platforms.keys())
            for tool_type, platforms in cls._adapters.items()
        }
```

##### 1.2.3 按工具功能的适配器实现示例

```python
import requests
import time
from typing import Dict, Any, Optional

# ===== 豆包基础连接类 =====
class DouBaoBase:
    """豆包基础连接类"""

    def __init__(self, config: Dict[str, Any]):
        self.api_key = config.get("api_key")
        self.base_url = config.get("base_url", "https://ark.cn-beijing.volces.com")
        self.default_model = config.get("default_model", "doubao-seedance-1-0-pro-250528")
        self.timeout = config.get("timeout", 60)
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _make_request(self, endpoint: str, payload: Dict = None, method: str = "POST") -> Dict:
        """发起HTTP请求的通用方法"""
        url = f"{self.base_url}{endpoint}"

        try:
            if method == "POST":
                response = requests.post(url, json=payload, headers=self.headers, timeout=self.timeout)
            elif method == "GET":
                response = requests.get(url, headers=self.headers, timeout=self.timeout)
            else:
                raise ValueError(f"不支持的HTTP方法: {method}")

            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            return {"success": False, "message": str(e)}

    def _poll_task_status(self, task_id: str, max_attempts: int = 60, interval: int = 10) -> Dict[str, Any]:
        """轮询任务状态直到完成"""
        for attempt in range(max_attempts):
            try:
                status_response = self._make_request(f"/api/v3/contents/generations/tasks/{task_id}", method="GET")

                if not status_response:
                    continue

                status = status_response.get("status")

                if status == "completed":
                    files = []
                    if "result" in status_response and "videos" in status_response["result"]:
                        files = [video["url"] for video in status_response["result"]["videos"]]
                    elif "result" in status_response and "images" in status_response["result"]:
                        files = [img["url"] for img in status_response["result"]["images"]]

                    return {"success": True, "files": files, "data": status_response}
                elif status == "failed":
                    error_msg = status_response.get("error", {}).get("message", "任务失败")
                    return {"success": False, "error_message": error_msg}
                elif status in ["pending", "processing"]:
                    time.sleep(interval)
                    continue
                else:
                    time.sleep(interval)
                    continue

            except Exception as e:
                if attempt == max_attempts - 1:
                    return {"success": False, "error_message": f"轮询任务状态失败: {str(e)}"}
                time.sleep(interval)

        return {"success": False, "error_message": f"任务超时，最大等待时间: {max_attempts * interval}秒"}

# ===== 豆包图生视频适配器（专业实现）=====
class DouBaoI2VAdapter(BaseI2VAdapter, DouBaoBase):
    """豆包图生视频适配器 - 专业实现"""

    def image_to_video(self, prompt: str, source_image: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包图生视频专业实现"""
        try:
            content = [
                {
                    "type": "text",
                    "text": self._build_video_prompt(prompt, aspect_ratio, **kwargs)
                },
                {
                    "type": "image_url",
                    "image_url": {"url": source_image}
                }
            ]

            payload = {
                "model": kwargs.get("model", self.default_model),
                "content": content
            }

            task_response = self._make_request("/api/v3/contents/generations/tasks", payload, method="POST")

            if not task_response.get("success") or "id" not in task_response:
                return AIModelResult(
                    success=False,
                    error_message=task_response.get("message", "创建任务失败")
                )

            video_result = self._poll_task_status(task_response["id"])

            if video_result["success"]:
                return AIModelResult(
                    success=True,
                    files=video_result["files"],
                    data=video_result["data"],
                    metadata={
                        "platform": "doubao",
                        "tool_type": "image_to_video",
                        "model": self.default_model,
                        "task_id": task_response["id"]
                    }
                )
            else:
                return AIModelResult(success=False, error_message=video_result["error_message"])

        except Exception as e:
            return AIModelResult(success=False, error_message=str(e))

    def _build_video_prompt(self, prompt: str, aspect_ratio: str, **kwargs) -> str:
        """构建豆包视频生成提示词"""
        video_prompt = prompt

        resolution_map = {
            "16:9": "1080p", "9:16": "720p", "1:1": "720p", "4:3": "720p"
        }
        resolution = resolution_map.get(aspect_ratio, "1080p")
        video_prompt += f" --resolution {resolution}"

        duration = kwargs.get("duration", 5)
        video_prompt += f" --duration {duration}"

        camera_fixed = kwargs.get("camera_fixed", False)
        video_prompt += f" --camerafixed {str(camera_fixed).lower()}"

        watermark = kwargs.get("watermark", True)
        video_prompt += f" --watermark {str(watermark).lower()}"

        return video_prompt

# ===== 豆包文生视频适配器（专业实现）=====
class DouBaoT2VAdapter(BaseT2VAdapter, DouBaoBase):
    """豆包文生视频适配器 - 专业实现"""

    def text_to_video(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包文生视频专业实现"""
        try:
            content = [{"type": "text", "text": self._build_video_prompt(prompt, aspect_ratio, **kwargs)}]
            payload = {"model": kwargs.get("model", self.default_model), "content": content}

            task_response = self._make_request("/api/v3/contents/generations/tasks", payload, method="POST")

            if not task_response.get("success") or "id" not in task_response:
                return AIModelResult(success=False, error_message=task_response.get("message", "创建任务失败"))

            video_result = self._poll_task_status(task_response["id"])

            if video_result["success"]:
                return AIModelResult(
                    success=True,
                    files=video_result["files"],
                    data=video_result["data"],
                    metadata={
                        "platform": "doubao",
                        "tool_type": "text_to_video",
                        "model": self.default_model,
                        "task_id": task_response["id"]
                    }
                )
            else:
                return AIModelResult(success=False, error_message=video_result["error_message"])

        except Exception as e:
            return AIModelResult(success=False, error_message=str(e))

    def _build_video_prompt(self, prompt: str, aspect_ratio: str, **kwargs) -> str:
        """构建视频提示词（与I2V共享逻辑）"""
        return DouBaoI2VAdapter._build_video_prompt(self, prompt, aspect_ratio, **kwargs)

# ===== 豆包其他工具适配器（基础实现，作为备用）=====
class DouBaoT2IAdapter(BaseT2IAdapter, DouBaoBase):
    """豆包文生图适配器 - 基础实现（备用）"""

    def text_to_image(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包文生图基础实现"""
        # TODO: 实现豆包文生图API
        return AIModelResult(success=False, error_message="豆包文生图接口待实现")

class DouBaoASRAdapter(BaseASR_Adapter, DouBaoBase):
    """豆包语音识别适配器 - 专业实现"""

    def speech_to_subtitle(self, audio_url: str, language: str, **kwargs) -> AIModelResult:
        """豆包语音识别专业实现"""
        # TODO: 实现豆包ASR API
        return AIModelResult(success=False, error_message="豆包ASR接口待实现")

# ===== 适配器注册示例 =====
def register_doubao_adapters():
    """注册豆包的所有工具适配器"""
    # 豆包的强项：视频生成
    ToolAdapterFactory.register_adapter("image_to_video", "doubao", DouBaoI2VAdapter)
    ToolAdapterFactory.register_adapter("text_to_video", "doubao", DouBaoT2VAdapter)
    ToolAdapterFactory.register_adapter("speech_to_subtitle", "doubao", DouBaoASRAdapter)

    # 豆包的备用功能
    ToolAdapterFactory.register_adapter("text_to_image", "doubao", DouBaoT2IAdapter)

# 通义千问适配器注册示例（专精图像生成）
def register_tongyi_adapters():
    """注册通义千问的工具适配器"""
    # 通义的强项：图像生成
    ToolAdapterFactory.register_adapter("text_to_image", "tongyi", TongYiT2IAdapter)
    ToolAdapterFactory.register_adapter("image_to_image", "tongyi", TongYiI2IAdapter)

    # 通义的备用功能
    ToolAdapterFactory.register_adapter("image_to_video", "tongyi", TongYiI2VAdapter)

# 文心一言适配器注册示例（专精音频处理）
def register_wenxin_adapters():
    """注册文心一言的工具适配器"""
    # 文心的强项：音频处理
    ToolAdapterFactory.register_adapter("generate_music", "wenxin", WenXinMusicAdapter)
    ToolAdapterFactory.register_adapter("text_to_speech", "wenxin", WenXinTTSAdapter)

    # 文心的备用功能
    ToolAdapterFactory.register_adapter("text_to_image", "wenxin", WenXinT2IAdapter)
```

##### 1.2.4 按工具功能的配置管理
```yaml
# config/tool_adapters.yaml
platforms:
  doubao:
    config:
      api_key: "${DOUBAO_API_KEY}"
      base_url: "https://ark.cn-beijing.volces.com"
      default_model: "doubao-seedance-1-0-pro-250528"
      timeout: 60
    capabilities:
      strong_tools: ["image_to_video", "text_to_video", "speech_to_subtitle"]
      backup_tools: ["text_to_image"]
      cost_level: "medium"
      quality_scores:
        image_to_video: 9.0
        text_to_video: 9.0
        speech_to_subtitle: 8.5
        text_to_image: 6.5

  tongyi:
    config:
      api_key: "${TONGYI_API_KEY}"
      base_url: "https://dashscope.aliyuncs.com"
      timeout: 30
    capabilities:
      strong_tools: ["text_to_image", "image_to_image"]
      backup_tools: ["image_to_video", "text_to_video"]
      cost_level: "low"
      quality_scores:
        text_to_image: 9.5
        image_to_image: 9.0
        image_to_video: 7.0

  wenxin:
    config:
      api_key: "${WENXIN_API_KEY}"
      base_url: "https://aip.baidubce.com"
      timeout: 45
    capabilities:
      strong_tools: ["generate_music", "text_to_speech"]
      backup_tools: ["text_to_image"]
      cost_level: "low"
      quality_scores:
        generate_music: 8.5
        text_to_speech: 8.8
        text_to_image: 6.0

# 工具选择策略
tool_strategy:
  primary_platforms:
    text_to_image: "tongyi"        # 通义质量最好
    image_to_image: "tongyi"       # 通义专业
    image_to_video: "doubao"       # 豆包专业
    text_to_video: "doubao"        # 豆包专业
    generate_music: "wenxin"       # 文心专业
    text_to_speech: "wenxin"       # 文心专业
    speech_to_subtitle: "doubao"   # 豆包专业

  fallback_platforms:
    text_to_image: ["doubao", "wenxin"]
    image_to_image: ["doubao", "wenxin"]
    image_to_video: ["tongyi", "wenxin"]
    text_to_video: ["tongyi", "wenxin"]
    generate_music: ["doubao", "tongyi"]
    text_to_speech: ["doubao", "tongyi"]
    speech_to_subtitle: ["tongyi", "wenxin"]
```

##### 1.2.5 按工具功能的智能选择器
```python
class ToolAdapterSelector:
    """按工具功能的智能适配器选择器"""

    def __init__(self, config):
        self.config = config
        self.strategy = config["tool_strategy"]
        self.factory = ToolAdapterFactory()
        self.performance_tracker = ToolPerformanceTracker()

    def get_best_adapter(self, tool_type: str, context: Dict = None):
        """为特定工具选择最佳适配器"""
        # 1. 获取首选平台
        primary_platform = self.strategy["primary_platforms"].get(tool_type)

        # 2. 检查首选平台是否可用
        if primary_platform and self._is_platform_available(tool_type, primary_platform):
            adapter = self.factory.create_adapter(tool_type, primary_platform,
                                                  self.config["platforms"][primary_platform]["config"])
            self._log_usage(tool_type, primary_platform, "primary")
            return adapter

        # 3. 使用降级策略
        fallback_platforms = self.strategy["fallback_platforms"].get(tool_type, [])
        for platform in fallback_platforms:
            if self._is_platform_available(tool_type, platform):
                adapter = self.factory.create_adapter(tool_type, platform,
                                                      self.config["platforms"][platform]["config"])
                self._log_usage(tool_type, platform, "fallback")
                return adapter

        # 4. 没有找到可用的平台
        available_platforms = self.factory.list_platforms(tool_type)
        raise Exception(f"工具 {tool_type} 没有可用的平台。可用平台: {available_platforms}")

    def _is_platform_available(self, tool_type: str, platform: str) -> bool:
        """检查平台对指定工具是否可用"""
        try:
            # 检查平台是否支持该工具
            if platform not in self.factory.list_platforms(tool_type):
                return False

            # 检查平台配置和质量要求
            platform_config = self.config["platforms"].get(platform, {})
            capabilities = platform_config.get("capabilities", {})

            # 检查质量分数
            quality_scores = capabilities.get("quality_scores", {})
            tool_quality = quality_scores.get(tool_type, 0)

            # 质量太低则不使用
            if tool_quality < 6.0:
                return False

            return self._health_check(platform)

        except Exception:
            return False

    def _health_check(self, platform: str) -> bool:
        """平台健康检查"""
        # TODO: 实现平台连通性检查
        return True

    def _log_usage(self, tool_type: str, platform: str, usage_type: str):
        """记录使用情况"""
        self.performance_tracker.record_usage(tool_type, platform, usage_type)

class AIToolExecutor:
    """按工具功能的AI工具执行器"""

    def __init__(self):
        self.config = load_config("tool_adapters.yaml")
        self.selector = ToolAdapterSelector(self.config)

    def execute_text2img_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行文生图工具 - 自动选择最佳平台（默认通义千问）"""
        adapter = self.selector.get_best_adapter("text_to_image")

        result = adapter.text_to_image(
            prompt=tool_request["input_data"]["prompt"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "text_to_image")

    def execute_img2video_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行图生视频工具 - 自动选择最佳平台（默认豆包）"""
        adapter = self.selector.get_best_adapter("image_to_video")

        result = adapter.image_to_video(
            prompt=tool_request["input_data"]["prompt"],
            source_image=tool_request["input_data"]["source_image_url"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "image_to_video")

    def execute_music_gen_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行音乐生成工具 - 自动选择最佳平台（默认文心）"""
        adapter = self.selector.get_best_adapter("generate_music")

        result = adapter.generate_music(
            prompt=tool_request["input_data"]["prompt"]
        )

        return self._format_result(result, "generate_music")

    def execute_img2img_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行图生图工具 - 自动选择最佳平台（默认通义千问）"""
        adapter = self.selector.get_best_adapter("image_to_image")

        result = adapter.image_to_image(
            prompt=tool_request["input_data"]["prompt"],
            source_image=tool_request["input_data"]["source_image_url"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "image_to_image")

    def execute_text2video_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行文生视频工具 - 自动选择最佳平台（默认豆包）"""
        adapter = self.selector.get_best_adapter("text_to_video")

        result = adapter.text_to_video(
            prompt=tool_request["input_data"]["prompt"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "text_to_video")

    def execute_text2speech_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行文案转语音工具 - 自动选择最佳平台（默认文心）"""
        adapter = self.selector.get_best_adapter("text_to_speech")

        result = adapter.text_to_speech(
            text=tool_request["input_data"]["text"],
            voice_id=tool_request["input_data"]["voice_id"],
            speed=tool_request["input_data"].get("speed", 1.0)
        )

        return self._format_result(result, "text_to_speech")

    def execute_speech2subtitle_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行语音转字幕工具 - 自动选择最佳平台（默认文心）"""
        adapter = self.selector.get_best_adapter("speech_to_subtitle")

        result = adapter.speech_to_subtitle(
            audio_url=tool_request["input_data"]["audio_url"],
            language=tool_request["input_data"].get("language", "zh-CN")
        )

        return self._format_result(result, "speech_to_subtitle")

    def execute_video_merge_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行视频合并工具 - 本地处理"""
        # 视频合并使用本地FFmpeg处理，不需要AI平台
        from .local_tools import VideoMerger

        merger = VideoMerger()
        result = merger.merge_videos(
            video_urls=tool_request["input_data"]["video_urls"],
            transition_type=tool_request["input_data"].get("transition_type", "fade")
        )

        return self._format_result_local(result, "video_merge")

    def execute_audio_video_merge_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行音视频合并工具 - 本地处理"""
        # 音视频合并使用本地FFmpeg处理
        from .local_tools import AudioVideoMerger

        merger = AudioVideoMerger()
        result = merger.merge_audio_video(
            video_url=tool_request["input_data"]["video_url"],
            audio_url=tool_request["input_data"]["audio_url"],
            audio_volume=tool_request["input_data"].get("audio_volume", 0.8)
        )

        return self._format_result_local(result, "audio_video_merge")

    def execute_subtitle_video_merge_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行字幕视频合并工具 - 本地处理"""
        # 字幕合并使用本地FFmpeg处理
        from .local_tools import SubtitleVideoMerger

        merger = SubtitleVideoMerger()
        result = merger.add_subtitle_to_video(
            video_url=tool_request["input_data"]["video_url"],
            subtitle_text=tool_request["input_data"]["subtitle_text"],
            font_size=tool_request["input_data"].get("font_size", 24)
        )

        return self._format_result_local(result, "subtitle_video_merge")

    def _format_result(self, result: AIModelResult, tool_type: str) -> Dict[str, Any]:
        """格式化结果"""
        if result.success:
            return {
                "success": True,
                "output_data": result.data,
                "original_files": result.files,
                "metadata": {
                    **result.metadata,
                    "tool_type": tool_type,
                    "selected_platform": result.metadata.get("platform", "unknown")
                }
            }
        else:
            return {
                "success": False,
                "error_message": result.error_message
            }

    def _format_result_local(self, result: Dict[str, Any], tool_type: str) -> Dict[str, Any]:
        """格式化本地工具结果"""
        if result.get("success", False):
            return {
                "success": True,
                "output_data": result.get("data", {}),
                "original_files": result.get("files", []),
                "metadata": {
                    "tool_type": tool_type,
                    "selected_platform": "local"
                }
            }
        else:
            return {
                "success": False,
                "error_message": result.get("error_message", "本地工具执行失败")
            }
```

##### 1.2.6 模型切换策略

**动态模型切换**：
```python
class AdapterSwitchStrategy:
    """适配器切换策略"""

    def __init__(self):
        self.performance_metrics = {}  # 性能指标记录
        self.cost_metrics = {}         # 成本指标记录
        self.failure_counts = {}       # 失败计数

    def should_switch_adapter(self, current_adapter: str, tool_type: str) -> Optional[str]:
        """判断是否应该切换适配器"""
        # 基于失败率切换
        if self.failure_counts.get(current_adapter, 0) > 3:
            return self._get_backup_adapter(current_adapter, tool_type)

        # 基于性能切换
        if self._is_performance_degraded(current_adapter, tool_type):
            return self._get_better_performance_adapter(tool_type)

        return None

    def _get_backup_adapter(self, failed_adapter: str, tool_type: str) -> str:
        """获取备用适配器"""
        backup_map = {
            "doubao": "tongyi",
            "tongyi": "wenxin",
            "wenxin": "doubao"
        }
        return backup_map.get(failed_adapter, "doubao")
```

**配置热更新**：
```python
class AdapterConfigManager:
    """适配器配置管理器"""

    def __init__(self):
        self.config_file = "tool_adapters.yaml"
        self.config_cache = {}
        self.last_modified = 0

    def get_current_config(self) -> Dict[str, Any]:
        """获取当前配置（支持热更新）"""
        current_modified = os.path.getmtime(self.config_file)
        if current_modified > self.last_modified:
            self.config_cache = self._load_config()
            self.last_modified = current_modified
        return self.config_cache

    def switch_default_adapter(self, tool_type: str, new_adapter: str):
        """切换默认适配器"""
        config = self.get_current_config()
        config[f"default_{tool_type}_adapter"] = new_adapter
        self._save_config(config)
```

##### 1.2.7 工具规范
- 每个工具必须有标准的输入输出格式
- 支持JSON Schema定义参数结构
- 统一的错误处理和状态报告
- 文件输入输出自动管理
- 支持多AI模型切换的适配器模式
- 配置驱动的模型选择机制
- 支持运行时动态切换和故障转移
- 性能监控和成本控制机制


##### 1.2.4 豆包API接口扩展计划

基于当前的图生视频接口实现模式，其他豆包API接口需要按照类似的异步任务模式实现：

**1. 文生图接口**
- 预计使用相同的任务创建和轮询模式
- endpoint: `/api/v3/contents/generations/tasks`
- 模型参数需要调整为图像生成模型

**2. 图生图接口**
- 与图生视频类似，需要在content中包含source_image
- 使用相同的任务管理API

**3. 音乐生成接口**
- 可能使用独立的音频生成API端点
- 需要支持音乐风格、时长等参数

**4. 文本转语音接口**
- 可能支持实时或近实时转换
- 需要支持不同的声音ID选择

**5. 语音转字幕接口**
- 需要上传音频文件
- 支持多语言识别

##### 1.2.4 混合平台配置管理
```yaml
# config/ai_adapters.yaml
adapters:
  doubao:
    class: "adapters.doubao.DouBaoAdapter"
    config:
      api_key: "${DOUBAO_API_KEY}"
      base_url: "https://ark.cn-beijing.volces.com"
      default_model: "doubao-seedance-1-0-pro-250528"
      timeout: 60
    capabilities:
      strengths: ["image_to_video", "text_to_video", "speech_to_subtitle"]
      cost_level: "medium"
      quality_score: 8.5

  tongyi:
    class: "adapters.tongyi.TongYiAdapter"
    config:
      api_key: "${TONGYI_API_KEY}"
      base_url: "https://dashscope.aliyuncs.com"
      default_model: "wanx-v1"
      timeout: 30
    capabilities:
      strengths: ["text_to_image", "image_to_image"]
      cost_level: "low"
      quality_score: 9.0

  wenxin:
    class: "adapters.wenxin.WenXinAdapter"
    config:
      api_key: "${WENXIN_API_KEY}"
      base_url: "https://aip.baidubce.com"
      timeout: 45
    capabilities:
      strengths: ["generate_music", "text_to_speech"]
      cost_level: "low"
      quality_score: 8.0

# 按功能分配最佳平台策略
platform_strategy:
  default_adapters:
    text_to_image: "tongyi"        # 文生图用通义（质量好）
    image_to_image: "tongyi"       # 图生图用通义
    image_to_video: "doubao"       # 图生视频用豆包（效果佳）
    text_to_video: "doubao"        # 文生视频用豆包
    generate_music: "wenxin"       # 音乐生成用文心（成本低）
    text_to_speech: "wenxin"       # 语音合成用文心
    speech_to_subtitle: "doubao"   # 语音识别用豆包

  # 降级策略：主平台不可用时的备选
  fallback_adapters:
    text_to_image: ["doubao", "wenxin"]
    image_to_image: ["doubao", "wenxin"]
    image_to_video: ["tongyi", "wenxin"]
    text_to_video: ["tongyi", "wenxin"]
    generate_music: ["doubao", "tongyi"]
    text_to_speech: ["doubao", "tongyi"]
    speech_to_subtitle: ["tongyi", "wenxin"]

  # 成本优化策略
  cost_optimization:
    enabled: true
    prefer_low_cost: true          # 优先使用低成本平台
    quality_threshold: 7.0         # 质量阈值，低于此分数不使用

  # 地域策略
  region_strategy:
    china:
      preferred: ["tongyi", "wenxin", "doubao"]
    international:
      preferred: ["openai", "claude"]
```

##### 1.2.5 按工具功能的智能选择器
```python
class ToolAdapterSelector:
    """按工具功能的智能适配器选择器"""

    def __init__(self, config):
        self.config = config
        self.strategy = config["tool_strategy"]
        self.factory = ToolAdapterFactory()
        self.performance_tracker = ToolPerformanceTracker()

    def get_best_adapter(self, tool_type: str, context: Dict = None):
        """为特定工具选择最佳适配器"""
        # 1. 获取首选平台
        primary_platform = self.strategy["primary_platforms"].get(tool_type)

        # 2. 检查首选平台是否可用
        if primary_platform and self._is_platform_available(tool_type, primary_platform):
            adapter = self.factory.create_adapter(tool_type, primary_platform,
                                                  self.config["platforms"][primary_platform]["config"])
            self._log_usage(tool_type, primary_platform, "primary")
            return adapter

        # 3. 使用降级策略
        fallback_platforms = self.strategy["fallback_platforms"].get(tool_type, [])
        for platform in fallback_platforms:
            if self._is_platform_available(tool_type, platform):
                adapter = self.factory.create_adapter(tool_type, platform,
                                                      self.config["platforms"][platform]["config"])
                self._log_usage(tool_type, platform, "fallback")
                return adapter

        # 4. 没有找到可用的平台
        available_platforms = self.factory.list_platforms(tool_type)
        raise Exception(f"工具 {tool_type} 没有可用的平台。可用平台: {available_platforms}")

    def _is_platform_available(self, tool_type: str, platform: str) -> bool:
        """检查平台对指定工具是否可用"""
        try:
            # 检查平台是否支持该工具
            if platform not in self.factory.list_platforms(tool_type):
                return False

            # 检查平台配置和质量要求
            platform_config = self.config["platforms"].get(platform, {})
            capabilities = platform_config.get("capabilities", {})

            # 检查质量分数
            quality_scores = capabilities.get("quality_scores", {})
            tool_quality = quality_scores.get(tool_type, 0)

            # 质量太低则不使用
            if tool_quality < 6.0:
                return False

            return self._health_check(platform)

        except Exception:
            return False

    def _health_check(self, platform: str) -> bool:
        """平台健康检查"""
        # TODO: 实现平台连通性检查
        return True

    def _log_usage(self, tool_type: str, platform: str, usage_type: str):
        """记录使用情况"""
        self.performance_tracker.record_usage(tool_type, platform, usage_type)
```



##### 1.2.6 模型切换策略

**动态模型切换**：
```python
class AdapterSwitchStrategy:
    """适配器切换策略"""

    def __init__(self):
        self.performance_metrics = {}  # 性能指标记录
        self.cost_metrics = {}         # 成本指标记录
        self.failure_counts = {}       # 失败计数

    def should_switch_adapter(self, current_adapter: str, tool_type: str) -> Optional[str]:
        """判断是否应该切换适配器"""
        # 基于失败率切换
        if self.failure_counts.get(current_adapter, 0) > 3:
            return self._get_backup_adapter(current_adapter, tool_type)

        # 基于性能切换
        if self._is_performance_degraded(current_adapter, tool_type):
            return self._get_better_performance_adapter(tool_type)

        return None

    def _get_backup_adapter(self, failed_adapter: str, tool_type: str) -> str:
        """获取备用适配器"""
        backup_map = {
            "doubao": "tongyi",
            "tongyi": "wenxin",
            "wenxin": "doubao"
        }
        return backup_map.get(failed_adapter, "doubao")
```

**配置热更新**：
```python
class AdapterConfigManager:
    """适配器配置管理器"""

    def __init__(self):
        self.config_file = "ai_adapters.yaml"
        self.config_cache = {}
        self.last_modified = 0

    def get_current_config(self) -> Dict[str, Any]:
        """获取当前配置（支持热更新）"""
        current_modified = os.path.getmtime(self.config_file)
        if current_modified > self.last_modified:
            self.config_cache = self._load_config()
            self.last_modified = current_modified
        return self.config_cache

    def switch_default_adapter(self, tool_type: str, new_adapter: str):
        """切换默认适配器"""
        config = self.get_current_config()
        config[f"default_{tool_type}_adapter"] = new_adapter
        self._save_config(config)
```

##### 1.2.7 工具规范
- 每个工具必须有标准的输入输出格式
- 支持JSON Schema定义参数结构
- 统一的错误处理和状态报告
- 文件输入输出自动管理
- 支持多AI模型切换的适配器模式
- 配置驱动的模型选择机制
- 支持运行时动态切换和故障转移
- 性能监控和成本控制机制

#### 1.2 工具节点（结构）

每个工具节点的通用结构包含以下一级字段：

```json
{
  "id": "number",                   // 数据库主键ID
  "node_id": "string",              // 节点唯一ID，格式：node_{uuid}
  "tool_uuid": "string",            // 工具UUID，固定值如tool-img-understand-001
  "tool_name": "string",            // 工具名称，如"图片理解"
  "step_index": "number",           // 执行步骤索引，从0开始递增
  "status": "number",               // 节点状态：0-待执行，1-执行中，2-已完成，3-失败
  "input_data": "object",           // 输入数据对象（结构根据工具类型而定）
  "output_data": "object",          // 输出数据对象（结构根据工具类型而定）
  "output_files": "array",          // 输出文件列表（项目存储objectName）
  "original_files": "array",        // 原始文件列表（第三方API返回链接）
  "preview_required": "boolean",    // 是否需要前端预览
  "error_message": "string",        // 错误信息详情
  "create_time": "string",          // 节点创建时间
  "update_time": "string",          // 节点更新时间
  "start_time": "string",           // 开始执行时间
  "end_time": "string",             // 执行完成时间
  "duration_ms": "number",          // 执行耗时（毫秒）
  "creator_id": "number",           // 创建者用户ID
  "workflow_id": "string",          // 所属工作流ID
  "parent_node_id": "string",       // 父节点ID（用于构建执行链）
  "child_node_ids": "array",        // 子节点ID列表
  "sort_order": "number",           // 在工作流中的排序顺序
  "retry_count": "number",          // 重试次数
  "max_retry": "number",            // 最大重试次数
  "execution_context": "object"     // 执行上下文（包含项目ID、任务ID等）
}
```

#### 字段详细说明

##### 基础信息字段
- **id**: 数据库自增主键，用于关联查询
- **node_id**: 节点唯一标识符，在工作流中唯一，格式通常为 `node_{timestamp}_{random}`
- **tool_uuid**: 工具的固定UUID标识，对应具体的AI工具功能
- **tool_name**: 工具的可读名称，用于前端显示
- **step_index**: 在工作流中的执行顺序，从0开始

##### 状态管理字段
- **status**: 节点执行状态，用于跟踪执行进度和错误处理
- **retry_count/max_retry**: 重试机制相关，支持失败重试
- **start_time/end_time/duration_ms**: 执行时间跟踪，用于性能监控

##### 数据字段
- **input_data**: 节点输入参数，结构根据工具类型动态变化
- **output_data**: 节点输出结果，包含主要结果和元数据信息
- **execution_context**: 执行上下文，包含项目、任务等关联信息

##### 文件管理字段
- **original_files**: 第三方API返回的原始文件链接，可能是临时的
- **output_files**: 转换后存储在项目文件系统中的文件信息
- 每个文件对象包含完整的元数据，便于文件管理和访问控制

##### 工作流关系字段
- **workflow_id**: 标识节点所属的工作流
- **parent_node_id/child_node_ids**: 构建节点间的依赖关系
- **sort_order**: 确保节点按正确顺序执行

##### 用户关联字段
- **creator_id**: 标识创建该节点的用户
- **preview_required**: 控制是否需要向前端推送预览结果

#### 文件处理机制说明

**original_files 字段**：
- 存储第三方API或本地API返回的原始文件链接
- 格式：`["https://api.example.com/files/abc123.jpg", "https://local.api/temp/video456.mp4"]`
- 这些文件可能是临时链接，需要及时下载和转存

**output_files 字段**：
- 存储项目文件存储系统中的objectName
- 格式：`["image/2024/12/abc123_processed.jpg", "video/2024/12/video456_final.mp4"]`
- 这些是持久化存储的文件标识，可长期访问

**文件转换流程**：
1. 工具执行完成后，从`original_files`中获取原始文件链接
2. 系统自动下载这些文件到本地临时目录
3. 将文件上传到项目配置的文件存储系统（MinIO/OSS等）
4. 获得objectName后存储到`output_files`字段
5. 清理本地临时文件
6. 返回处理后的节点数据给前端

##### 1. 文生图节点
```json
{
  "tool_uuid": "tool-text2img-001",
  "tool_name": "文生图",
  "input_data": {
    "prompt": "string",             // 图片提示词
    "aspect_ratio": "string"         // 图片比例："1:1", "16:9", "9:16", "4:3"
  },
  "output_data": {
    "image_info": "object"          // 图片信息
  },
  "output_files": ["image_url"],
  "original_files": ["image_url"],
  "preview_required": true
}
```

##### 2. 图生图节点
```json
{
  "tool_uuid": "tool-img2img-002",
  "tool_name": "图生图",
  "input_data": {
    "prompt": "string",             // 图片提示词
    "source_image_url": "string",   // 源图片URL
    "aspect_ratio": "string"         // 图片比例："1:1", "16:9", "9:16", "4:3"
  },
  "output_data": {
    "image_info": "object"          // 图片信息
  },
  "output_files": ["image_url"],
  "original_files": ["image_url"],
  "preview_required": true
}
```

##### 3. 图生视频节点
```json
{
  "tool_uuid": "tool-img2video-003",
  "tool_name": "图生视频",
  "input_data": {
    "prompt": "string",             // 视频提示词
    "source_image_url": "string",   // 源图片URL（可选）
    "aspect_ratio": "string"         // 视频比例："16:9", "9:16", "1:1"
  },
  "output_data": {
    "video_info": "object"          // 视频信息
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

##### 4. 文生视频节点
```json
{
  "tool_uuid": "tool-text2video-004",
  "tool_name": "文生视频",
  "input_data": {
    "prompt": "string",             // 视频提示词
    "aspect_ratio": "string"         // 视频比例："16:9", "9:16", "1:1"
  },
  "output_data": {
    "video_info": "object"          // 视频信息
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```


##### 5. 背景音乐生成节点
```json
{
  "tool_uuid": "tool-music-gen-005",
  "tool_name": "背景音乐生成",
  "input_data": {
    "prompt": "string"              // 音乐描述
  },
  "output_data": {
    "music_info": "object"          // 音乐信息
  },
  "output_files": ["audio_url"],
  "original_files": ["audio_url"],
  "preview_required": true
}
```


##### 6. 文案转语音节点
```json
{
  "tool_uuid": "tool-text2speech-008",
  "tool_name": "文案转语音",
  "input_data": {
    "text": "string",               // 待转换文本
    "voice_id": "string",          // 声音ID
    "speed": "number",             // 语速 (0.5-2.0)
    "pitch": "number",             // 音调 (0.5-2.0)
    "volume": "number"             // 音量 (0.0-1.0)
  },
  "output_data": {
    "audio_info": "object"         // 音频信息
  },
  "output_files": ["audio_url"],
  "original_files": ["audio_url"],
  "preview_required": true
}
```

##### 7. 语音生成字幕节点
```json
{
  "tool_uuid": "tool-speech2sub-009",
  "tool_name": "语音生成字幕",
  "input_data": {
    "audio_url": "string",         // 音频文件URL
    "language": "string",          // 语言代码 (zh-CN, en-US等)
    "format": "string"             // 字幕格式 (srt, vtt, ass)
  },
  "output_data": {
    "subtitle_info": "object",     // 字幕信息
    "word_count": "number",        // 词数
    "segments": "array"            // 字幕片段
  },
  "output_files": ["subtitle_url"],
  "original_files": ["subtitle_url"],
  "preview_required": false
}
```

##### 8. 视频合并节点
```json
{
  "tool_uuid": "tool-video-merge-010",
  "tool_name": "视频合并",
  "input_data": {
    "video_urls": "array"         // 视频文件URL列表
  },
  "output_data": {
    "merged_video_info": "object" // 合并后视频信息
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

##### 9. 音视频合并节点
```json
{
  "tool_uuid": "tool-av-merge-011",
  "tool_name": "音视频合并",
  "input_data": {
    "video_url": "string",         // 视频文件URL
    "audio_url": "string"         // 音频文件URL
  },
  "output_data": {
    "merged_video_info": "object" // 合并后视频信息
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

##### 10. 字幕视频合并节点
```json
{
  "tool_uuid": "tool-sub-merge-012",
  "tool_name": "字幕视频合并",
  "input_data": {
    "video_url": "string",         // 视频文件URL
    "subtitle_url": "string"      // 字幕文件URL
  },
  "output_data": {
    "final_video_info": "object"  // 最终视频信息
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

### 2. 任务执行页面重构

#### 2.1 页面布局需求
用户端前端项目的首页中有一个输入框，点击提交时会跳转到【任务中心页面】(`http://localhost:3000/ai-task`)。

**当前任务执行页面需要重构，参考设计截图**：/mnt/d/software/beilv-agent/任务执行页面.png

- **左侧面板**：显示历史项目列表
  - 支持项目搜索和分类
  - 点击项目可以加载并在右侧查看详细内容
  - 项目状态显示（进行中、已完成、失败等）

- **右侧面板**：对话框界面
  - 只支持一轮对话（用户输入 → AI执行 → 完成）
  - 用户可以输入任意要求
  - 实时显示工作流执行过程
  - 中间结果预览（图片、视频、音频）

#### 2.2 交互流程
1. **输入阶段**：用户输入提示词，可选择上传参考图片（0-6张）
   - **纯文字模式**：仅输入提示词，系统通过文生图→图生视频或直接文生视频
   - **图片辅助模式**：上传1-6张参考图片，结合提示词进行图生图→图生视频
   - **混合模式**：部分图片+文字描述，灵活组合生成内容
2. **分析阶段**：Python后端LLM分析提示词和上传内容，生成动态工作流
3. **执行阶段**：按顺序执行工作流节点，实时反馈进度
4. **预览阶段**：每个节点完成后，立即在对话框中预览结果
5. **完成阶段**：所有节点执行完成，生成最终视频

#### 2.3 实时反馈需求
提交提示词后，后端会按顺序输出中间结果，例如：
- 先生成图片 → 对话框预览图片
- 然后生成视频 → 对话框预览视频
- 创建背景音乐 → 对话框预览音频
- 创建广告口播 → 对话框预览音频和文案
- 最后合成视频 → 对话框预览最终视频

### 3. 项目任务创建流程

#### 3.1 项目创建
用户提交提示词后（可包含0-6张图片），后端创建一个空项目：
- 项目状态：初始状态
- 存储用户输入的提示词
- 用户上传的文件先上传到文件存储服务，获取objectName后存储到数据库中
- 分配唯一的项目ID
- **LLM智能内容分析**：通过RPC调用Python服务，LLM根据用户输入智能判断并执行相应的分析步骤：
  - **内容解析**：理解用户需求和创作意图（所有场景必需）
  - **图片理解**：仅当用户上传图片时执行，分析图片内容生成详细描述
  - **生成图片提示词**：仅当需要图片生成时执行，优化图片生成提示词
  - **生成视频提示词**：仅当需要视频生成时执行，优化视频生成提示词
  - **口播文案生成**：仅当需要语音/文案时执行，生成合适的口播内容
  - **工作流模式确定**：根据用户需求智能选择最适合的工作流模式
  - **完整执行计划生成**：基于确定的模式生成包含执行顺序的工作流JSON，为每个节点预设参数

**智能分析特点**：
- **按需分析**：只执行用户需求相关的分析步骤，避免不必要的处理
- **场景适配**：不同输入场景触发不同的分析流程
- **效率优化**：简单需求快速处理，复杂需求全面分析
- 将LLM分析结果和完整工作流配置存储到项目数据中
- **项目状态更新**：从"初始状态"转为"分析完成"，准备执行阶段

#### 3.2 工作流执行启动
项目创建和LLM分析完成后，系统自动启动工作流执行：

**执行启动流程**：
- **异步RPC调用**：Java后端通过RPC异步调用Python服务执行工作流
- **立即响应**：RPC调用后立即返回成功状态，不等待执行完成，避免长时间阻塞
- **项目状态更新**：项目状态从"分析完成"转为"执行中"
- **执行权转移**：Python端Agent接管工作流执行，Java端专注状态管理

**RPC接口设计**：
```java
// Java端异步调用
CompletableFuture<Void> future = pythonRpcService.executeWorkflowAsync(projectId, workflowConfig);
return ResponseEntity.ok("工作流执行已启动");
```

**执行参数传递**：
- 项目ID和工作流配置
- 完整的节点参数和提示词
- 文件存储配置信息
- 回调接口地址

#### 3.3 工作流执行过程
Python端接收到工作流执行请求后，采用Agent主导的执行模式：

**执行架构**：
- **Python Agent主导**：负责langchain工具链的具体执行
- **Java端状态管理**：通过回调接口实时接收状态更新
- **异步非阻塞**：执行过程不影响用户的其他操作

**节点执行流程**：
```python
async def execute_workflow(project_id, workflow):
    for node in workflow.nodes:
        # 1. 节点开始执行 - 回调通知Java端
        await callback_java_api(project_id, node.id, "running", None)

        try:
            # 2. 执行具体的AI工具
            result = await execute_node(node)

            # 3. 上传生成文件到存储服务
            if result.output_files:
                file_urls = await upload_files_to_storage(result.output_files)
                result.file_object_names = file_urls

            # 4. 节点执行完成 - 回调通知Java端
            await callback_java_api(project_id, node.id, "completed", result)

        except Exception as e:
            # 5. 节点执行失败 - 回调通知Java端
            await callback_java_api(project_id, node.id, "failed", str(e))
            break

        # 6. 更新项目整体进度
        progress = calculate_progress(workflow, current_node)
        await update_project_progress(project_id, progress)
```

**状态同步机制**：
- **实时回调**：每个节点状态变化立即通知Java端
- **数据持久化**：Java端接收回调后更新数据库状态
- **错误处理**：异常情况下回滚状态并通知用户
- **进度追踪**：实时计算和更新项目执行进度

**Java端回调接口**：
```java
@PostMapping("/api/workflow/callback")
public ResponseEntity<?> workflowCallback(@RequestBody CallbackRequest request) {
    // 更新节点状态和结果
    workflowService.updateNodeStatus(
        request.getProjectId(),
        request.getNodeId(),
        request.getStatus(),
        request.getResult()
    );

    // 更新项目状态
    if (request.getStatus().equals("failed")) {
        projectService.updateStatus(request.getProjectId(), "执行失败");
    }

    return ResponseEntity.ok();
}
```

**文件管理**：
- 每个节点生成的文件先上传到文件存储服务
- 获取objectName后通过回调传递给Java端
- Java端将objectName保存到数据库的节点输出字段

#### 3.4 工作流示例

**场景1：图片辅助视频制作（有上传图片）**
```text
图生图1->图生图2->图生图3->图生视频1->图生视频2->图生视频3->文案转语音->语音生成字幕->背景音乐生成->视频合并->音视频合并1->音视频合并2->字幕视频合并
```
*用户输入：制作香水广告视频* + 上传3张图片
*LLM分析：图片理解 → 内容解析 → 生成图片提示词 → 生成视频提示词 → 口播文案生成 → 工作流模式确定（完整视频制作）*

**场景2：纯文字视频制作（无上传图片）**
```text
文生图1->文生图2->文生图3->图生视频1->图生视频2->图生视频3->文案转语音->语音生成字幕->背景音乐生成->视频合并->音视频合并1->音视频合并2->字幕视频合并
```
*用户输入：制作美食推广视频*
*LLM分析：内容解析 → 生成图片提示词 → 生成视频提示词 → 口播文案生成 → 工作流模式确定（完整视频制作）*

**场景3：直接文生视频制作**
```text
文生视频1->文生视频2->文生视频3->文案转语音->语音生成字幕->背景音乐生成->视频合并->音视频合并1->音视频合并2->字幕视频合并
```
*用户输入：直接生成科技产品演示视频*
*LLM分析：内容解析 → 生成视频提示词 → 口播文案生成 → 工作流模式确定（文生视频制作）*

**场景4：纯口播文案场景**
```text
文案转语音
```
*用户输入：帮我生成一段卖内衣的口播文案以及配音*
*LLM分析：内容解析 → 口播文案生成 → 工作流模式确定（文案转语音）*

**场景5：纯图片生成场景**
```text
文生图1->文生图2
```
*用户输入：帮我生成两张沙滩美女图片*
*LLM分析：内容解析 → 生成图片提示词 → 工作流模式确定（多图生成）*

**场景6：音频处理场景**
```text
语音生成字幕
```
*用户输入：帮我为这段音频生成字幕* + 上传音频文件
*LLM分析：内容解析 → 工作流模式确定（音频转字幕）*

**场景7：图片优化场景**
```text
图生图1->图生图2->图生图3
```
*用户输入：帮我优化这些产品图片* + 上传3张图片
*LLM分析：图片理解 → 内容解析 → 生成图片提示词 → 工作流模式确定（图片优化）*

#### 3.5 智能工作流模式确定逻辑

LLM根据以下因素智能判断工作流模式：

**输入类型判断**：
- **有上传图片** → 优先考虑图片相关处理（图生图、图生视频）
- **有上传音频** → 音频处理模式（语音转字幕、音频优化）
- **纯文字输入** → 根据需求内容判断生成类型

**需求关键词识别**：
- **包含"文案"、"配音"、"口播"** → 文案转语音模式
- **包含"图片"、"照片"、"生成图"** → 图片生成模式
- **包含"视频"、"广告"、"宣传片"** → 视频制作模式
- **包含"字幕"、"转录"** → 语音转字幕模式
- **包含"优化"、"美化"** + 上传文件 → 文件优化模式

**复杂度评估**：
- **简单单一需求**：生成最精简的工作流（如单纯文案转语音）
- **中等复杂需求**：生成中等长度工作流（如多图生成）
- **复杂综合需求**：生成完整工作流（如完整视频制作）

**智能优化**：
- 根据用户历史偏好调整工作流结构
- 自动排除不必要的处理步骤
- 优化节点顺序以提高执行效率

这种智能模式确定机制确保每个用户需求都能得到最合适、最高效的工作流配置。

### 4. Langchain工具链执行细节

#### 4.1 工具链架构
Python端使用langchain框架管理AI工具的调用和协调：

**核心组件**：
- **工具注册器**：管理所有AI工具（文生图、图生视频、语音合成等）
- **执行调度器**：按照工作流顺序调度工具执行
- **状态管理器**：跟踪每个节点的执行状态
- **回调处理器**：负责与Java端的状态同步

#### 4.2 工具执行流程
```python
class WorkflowExecutor:
    async def execute_node(self, node):
        # 1. 获取节点对应的工具
        tool = self.tool_registry.get_tool(node.tool_type)

        # 2. 准备输入参数
        input_params = self.prepare_input_params(node)

        # 3. 执行工具
        result = await tool.execute(input_params)

        # 4. 处理输出文件
        if result.output_files:
            result.file_urls = await self.upload_files(result.output_files)

        # 5. 返回执行结果
        return result
```

#### 4.3 执行示例
以香氛产品视频为例的实际执行过程：

**执行序列**：
1. **图生图1**：输入图片1 + 提示词 → 优化图片1 → 回调更新状态
2. **图生图2**：输入图片2 + 提示词 → 优化图片2 → 回调更新状态
3. **图生图3**：输入图片3 + 提示词 → 优化图片3 → 回调更新状态
4. **图生视频1**：优化图片1 → 视频片段1 → 回调更新状态
5. **图生视频2**：优化图片2 → 视频片段2 → 回调更新状态
6. **图生视频3**：优化图片3 → 视频片段3 → 回调更新状态
7. **文案转语音**：预生成文案 → 语音文件 → 回调更新状态
8. **语音生成字幕**：语音文件 → 字幕文件 → 回调更新状态
9. **背景音乐生成**：风格参数 → 背景音乐 → 回调更新状态
10. **视频合并**：3个视频片段 → 主视频 → 回调更新状态
11. **音视频合并1**：主视频+背景音乐 → 带音乐视频 → 回调更新状态
12. **音视频合并2**：带音乐视频+语音 → 完整音频视频 → 回调更新状态
13. **字幕视频合并**：完整音频视频+字幕 → 最终视频 → 项目完成

**关键特性**：
- 每个步骤完成后立即通过回调更新Java端状态
- 生成的文件实时上传到存储服务并获取objectName
- 前端可以实时查看每个节点的执行结果和预览

#### 4.4 错误处理和重试机制
- **工具执行失败**：记录错误信息，回调通知Java端，终止后续执行
- **网络异常**：自动重试机制，最多重试3次
- **文件上传失败**：重试文件上传，失败则回滚节点状态
- **状态同步失败**：本地保存状态，后续批量同步

### 5. 文件上传和转换服务设计

#### 5.1 服务架构

**Java后端文件转换服务**：
```java
@Service
public class FileConversionService {

    @Autowired
    private FileStorageService fileStorageService;

    /**
     * 将original_files转换为output_files
     * @param originalFiles 原始文件URL列表
     * @param nodeId 节点ID，用于生成对象名称
     * @return 转换后的objectName列表
     */
    public List<String> convertFilesToStorage(List<String> originalFiles, String nodeId) {
        List<String> objectNames = new ArrayList<>();
        List<File> tempFiles = new ArrayList<>();

        try {
            for (int i = 0; i < originalFiles.size(); i++) {
                String originalUrl = originalFiles.get(i);

                // 1. 下载原始文件到临时目录
                File tempFile = downloadFile(originalUrl, nodeId + "_" + i);
                tempFiles.add(tempFile);

                // 2. 使用FileStorageService上传到存储系统
                MultipartFile multipartFile = convertToMultipartFile(tempFile);
                FileStorageService.FileUploadResult result = fileStorageService.uploadFile(multipartFile);
                objectNames.add(result.getObjectName());
            }
        } finally {
            // 3. 清理临时文件
            cleanupTempFiles(tempFiles);
        }

        return objectNames;
    }

    /**
     * 下载原始文件到临时目录
     */
    private File downloadFile(String originalUrl, String fileName) {
        // 实现文件下载逻辑
        // 从originalUrl下载文件到临时目录
    }

    /**
     * 将File转换为MultipartFile
     */
    private MultipartFile convertToMultipartFile(File file) {
        // 实现File到MultipartFile的转换
    }

    /**
     * 清理临时文件
     */
    private void cleanupTempFiles(List<File> tempFiles) {
        for (File file : tempFiles) {
            if (file.exists()) {
                file.delete();
            }
        }
    }
}
```

#### 5.2 转换流程

**步骤1：原始文件下载**
- 从original_files数组中获取所有原始文件链接
- 并发下载文件到临时目录：`/tmp/tool-files/{nodeId}/`
- 根据文件扩展名确定文件类型（image/video/audio）
- 下载失败时记录错误并跳过该文件

**步骤2：文件上传存储**
- 根据文件类型和当前日期生成存储路径：`{type}/{year}/{month}/{filename}`
- 调用OSS服务上传文件
- 获得objectName并添加到output_files数组
- 记录上传结果和耗时

**步骤3：临时文件清理**
- 上传成功后立即删除本地临时文件
- 定期清理超时的临时文件（1小时后自动清理）
- 异常情况下确保临时文件不会堆积

#### 5.3 异常处理

**下载失败处理**：
- 记录失败的原始链接和错误原因
- 设置重试机制（最多3次）
- 部分文件失败不影响其他文件处理
- 在节点error_message中记录失败详情

**上传失败处理**：
- 记录上传失败的文件和错误原因
- 保留已成功上传的文件objectName
- 设置重试机制
- 通知前端部分文件处理失败

#### 5.4 配置参数

```yaml
file.conversion:
  temp-dir: /tmp/tool-files/
  download-timeout: 30s
  upload-timeout: 60s
  max-file-size: 100MB
  retry-times: 3
  cleanup-interval: 1h
  supported-formats:
    image: [jpg, jpeg, png, gif, webp]
    video: [mp4, avi, mov, mkv]
    audio: [mp3, wav, aac, flac]
```

### 6. LLM预处理服务设计

#### 6.1 预处理流程

**输入**：
- 用户提示词：文字描述需求
- 上传图片：0-6张参考图片（可选）

**LLM处理步骤**：
1. **需求分析**：理解用户意图、风格要求、输出规格等
2. **图片理解**：调用视觉模型分析上传的图片，生成详细描述
3. **提示词优化**：基于需求和图片分析，生成专业的AI提示词
4. **工作流规划**：确定执行路径和工具序列
5. **参数预设**：为每个工具节点预设优化的参数

**输出**：
- 完整的工作流JSON，包含所有节点的预设提示词
- 图片分析结果（用于项目记录）
- 执行策略说明

#### 6.2 提示词生成策略

**图片提示词生成**：
```python
def generate_image_prompt(user_input, image_analysis):
    # 结合用户需求和图片特征
    # 添加专业摄影术语
    # 优化艺术风格描述
    # 确保AI生成质量
    return optimized_prompt
```

**视频提示词生成**：
```python
def generate_video_prompt(user_input, image_prompt=None):
    # 添加镜头运动描述
    # 指定时长和帧率
    # 优化动作和转场
    # 确保视频连贯性
    return optimized_prompt
```

### 7. 关键技术难点

#### 5.1 动态工作流参数传递
**问题**：如何保证动态生成的工作流（工具链）能够正常执行衔接，不至于入参混乱错误？

**解决方案**：
- 使用JSON Schema定义工具输入输出格式
- LLM生成工作流时包含详细的参数映射规则
- 运行时动态解析和验证参数
- 工具调用前进行参数类型检查和转换

#### 5.2 任务中断恢复
**问题**：如何能够在工作流运行中突然宕机然后重启后能够继续恢复任务？

**解决方案**：
- 每个节点执行后立即保存状态到数据库
- 记录当前执行位置和中间结果
- 重启时从最后成功节点继续执行
- 文件引用使用objectName确保持久化

#### 5.3 文件自动管理
**问题**：如何能够自动下载需要的文件数据以及自动上传输出的文件数据？

**解决方案**：
- 节点执行前自动从文件存储下载所需文件
- 节点完成后自动上传输出文件到文件存储
- 临时文件目录管理和清理
- 文件URL生成和访问权限控制

#### 5.4 预览结果控制
**问题**：如何设置工具链中，哪些工具的结果需要返回前端并预览，哪些工具结果不做预览直接下一步？

**解决方案**：
- 工具定义中包含`preview_required`字段
- 重要的中间结果（图片、视频、音频）需要预览
- 纯文本处理结果可以不预览
- 支持配置化的预览策略

#### 5.5 实时状态推送
**问题**：如何在工作流运行中动态返回生成的结果并实时交互通知前端显示流程中间结果？

**架构设计**：
```
前端 ←→ Java后端WebSocket ←← Python回调接口
```

**实现方案**：

**1. 前端WebSocket连接**：
```javascript
// 前端通过项目ID建立WebSocket连接
const ws = new WebSocket(`ws://localhost:8080/ws/project/${projectId}`);

ws.onmessage = function(event) {
    const message = JSON.parse(event.data);
    handleWorkflowUpdate(message);
};
```

**2. Java端WebSocket管理**：
```java
@Component
@ServerEndpoint("/ws/project/{projectId}")
public class WorkflowWebSocketHandler {

    // 维护项目ID到WebSocket会话的映射
    private static Map<String, Session> projectSessions = new ConcurrentHashMap<>();

    @OnOpen
    public void onOpen(@PathParam("projectId") String projectId, Session session) {
        projectSessions.put(projectId, session);
        log.info("项目 {} 建立WebSocket连接", projectId);
    }

    @OnClose
    public void onClose(@PathParam("projectId") String projectId) {
        projectSessions.remove(projectId);
        log.info("项目 {} 关闭WebSocket连接", projectId);
    }

    /**
     * 向指定项目推送消息
     */
    public static void pushToProject(String projectId, WorkflowMessage message) {
        Session session = projectSessions.get(projectId);
        if (session != null && session.isOpen()) {
            try {
                session.getBasicRemote().sendText(JSON.toJSONString(message));
            } catch (IOException e) {
                log.error("推送消息失败", e);
            }
        }
    }
}
```

**3. Python回调接口**：
```java
@RestController
@RequestMapping("/api/workflow")
public class WorkflowCallbackController {

    @PostMapping("/callback/status")
    public ResponseEntity<?> workflowStatusCallback(@RequestBody StatusCallbackRequest request) {
        // 1. 更新数据库状态
        workflowService.updateNodeStatus(request.getProjectId(),
                                       request.getNodeId(),
                                       request.getStatus(),
                                       request.getResult());

        // 2. 构建WebSocket推送消息
        WorkflowMessage message = WorkflowMessage.builder()
            .type("node_status")
            .projectId(request.getProjectId())
            .nodeId(request.getNodeId())
            .status(request.getStatus())
            .result(request.getResult())
            .timestamp(System.currentTimeMillis())
            .build();

        // 3. 推送到前端
        WorkflowWebSocketHandler.pushToProject(request.getProjectId(), message);

        return ResponseEntity.ok();
    }
}
```

**4. Python端回调实现**：
```python
async def callback_java_api(project_id: str, node_id: str, status: str, result: dict = None):
    """回调Java接口更新状态并触发WebSocket推送"""
    callback_data = {
        "projectId": project_id,
        "nodeId": node_id,
        "status": status,  # running, completed, failed
        "result": result,
        "timestamp": int(time.time() * 1000)
    }

    async with aiohttp.ClientSession() as session:
        await session.post(
            f"{JAVA_BACKEND_URL}/api/workflow/callback/status",
            json=callback_data
        )
```

**5. 消息格式定义**：
```json
{
  "type": "node_status",           // 消息类型
  "projectId": "project_123",      // 项目ID
  "nodeId": "node_001",           // 节点ID
  "status": "completed",          // 状态：running/completed/failed
  "result": {                     // 节点执行结果
    "output_data": {},
    "output_files": ["objectName1", "objectName2"],
    "file_urls": ["url1", "url2"]  // 前端预览用的完整URL
  },
  "timestamp": 1634567890123      // 时间戳
}
```

**6. 前端处理逻辑**：
```javascript
function handleWorkflowUpdate(message) {
    switch(message.type) {
        case 'node_status':
            updateNodeUI(message.nodeId, message.status);
            if (message.result && message.result.file_urls) {
                showPreviewFiles(message.result.file_urls);
            }
            break;
        case 'workflow_complete':
            showFinalResult(message.result);
            break;
        case 'error':
            showErrorMessage(message.error);
            break;
    }
}
```

**优势**：
- **解耦合**：Python专注执行，Java专注连接管理
- **实时性**：节点状态变化立即推送到前端
- **可靠性**：通过回调接口保证消息投递
- **扩展性**：支持多种消息类型和多项目并发

## 数据库设计

### 1. AI项目表 (ai_project)
```sql
CREATE TABLE ai_project (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    prompt TEXT NOT NULL,           -- 用户输入的提示词
    uploaded_files JSON,            -- 上传的文件列表
    status INT DEFAULT 0,           -- 0:创建中 1:执行中 2:已完成 3:失败
    member_id BIGINT NOT NULL,      -- 所属用户ID
    create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

### 2. AI任务表 (ai_task)
```sql
CREATE TABLE ai_task (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    project_id BIGINT NOT NULL,
    task_type VARCHAR(100) NOT NULL,
    status INT DEFAULT 0,           -- 0:待执行 1:执行中 2:已完成 3:失败
    workflow_json TEXT,             -- 工作流定义JSON
    current_step INT DEFAULT 0,     -- 当前执行步骤
    total_steps INT DEFAULT 0,      -- 总步骤数
    python_task_id VARCHAR(100),    -- Python后端任务ID
    result_files JSON,              -- 最终结果文件列表
    create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

### 3. 工作流执行记录表 (ai_workflow_execution)
```sql
CREATE TABLE ai_workflow_execution (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    task_id BIGINT NOT NULL,
    node_id VARCHAR(100) NOT NULL,      -- 节点唯一ID
    tool_uuid VARCHAR(100) NOT NULL,    -- 工具UUID
    tool_name VARCHAR(100) NOT NULL,    -- 工具名称
    step_index INT NOT NULL,            -- 步骤索引
    status INT DEFAULT 0,               -- 0:待执行 1:执行中 2:已完成 3:失败
    input_data TEXT,                    -- 输入数据JSON
    output_data TEXT,                   -- 输出数据JSON
    output_files JSON,                  -- 输出文件列表（项目存储objectName）
    original_files JSON,                -- 原始文件列表（第三方API返回链接）
    preview_required BOOLEAN DEFAULT FALSE, -- 是否需要前端预览
    error_message TEXT,                 -- 错误信息
    start_time DATETIME,
    end_time DATETIME,
    duration_ms INT,                    -- 执行耗时(毫秒)
    creator_id BIGINT,                  -- 创建者ID
    workflow_id VARCHAR(100),           -- 工作流ID
    parent_node_id VARCHAR(100),        -- 父节点ID
    sort_order INT                      -- 节点排序
);
```

### 4. AI工具注册表 (ai_tool)
```sql
CREATE TABLE ai_tool (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    tool_uuid VARCHAR(100) UNIQUE NOT NULL,  -- 工具UUID
    tool_name VARCHAR(100) NOT NULL,         -- 工具名称
    tool_description TEXT,                   -- 工具描述
    tool_type VARCHAR(50) NOT NULL,          -- 工具类型(image,video,audio,text)
    input_schema JSON,                       -- 输入参数Schema
    output_schema JSON,                      -- 输出参数Schema
    preview_required BOOLEAN DEFAULT FALSE,  -- 是否需要前端预览
    is_local BOOLEAN DEFAULT FALSE,          -- 是否本地工具
    api_endpoint VARCHAR(255),               -- API端点
    status INT DEFAULT 1,                    -- 工具状态 0:禁用 1:启用
    create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

### 7. 实现示例

#### 7.1 文件转换服务实现

```java
@Service
@Slf4j
public class FileConversionServiceImpl implements FileConversionService {

    @Autowired
    private OssService ossService;

    @Value("${file.conversion.temp-dir:/tmp/tool-files/}")
    private String tempDir;

    @Value("${file.conversion.retry-times:3}")
    private int retryTimes;

    @Override
    public List<String> convertFilesToStorage(List<String> originalFiles, String nodeId) {
        if (CollectionUtils.isEmpty(originalFiles)) {
            return new ArrayList<>();
        }

        List<String> outputFiles = new ArrayList<>();
        List<File> tempFiles = new ArrayList<>();

        try {
            // 创建临时目录
            String nodeTempDir = tempDir + "/" + nodeId;
            FileUtils.forceMkdir(new File(nodeTempDir));

            // 并发下载原始文件
            List<CompletableFuture<DownloadResult>> downloadFutures = originalFiles.stream()
                .map(url -> CompletableFuture.supplyAsync(() -> downloadWithRetry(url, nodeTempDir)))
                .collect(Collectors.toList());

            // 等待所有下载完成
            CompletableFuture.allOf(downloadFutures.toArray(new CompletableFuture[0])).join();

            // 处理下载结果
            for (CompletableFuture<DownloadResult> future : downloadFutures) {
                DownloadResult result = future.get();
                if (result.isSuccess()) {
                    tempFiles.add(result.getFile());

                    // 上传到存储系统
                    String objectName = uploadWithRetry(result.getFile());
                    if (objectName != null) {
                        outputFiles.add(objectName);
                    }
                } else {
                    log.error("文件下载失败: {}, 错误: {}", result.getOriginalUrl(), result.getError());
                }
            }

        } catch (Exception e) {
            log.error("文件转换服务异常", e);
        } finally {
            // 清理临时文件
            cleanupTempFiles(tempFiles);
        }

        return outputFiles;
    }

    private DownloadResult downloadWithRetry(String originalUrl, String tempDir) {
        for (int i = 0; i < retryTimes; i++) {
            try {
                File file = downloadFile(originalUrl, tempDir);
                return DownloadResult.success(file, originalUrl);
            } catch (Exception e) {
                log.warn("第{}次下载失败: {}, 错误: {}", i + 1, originalUrl, e.getMessage());
                if (i == retryTimes - 1) {
                    return DownloadResult.failure(originalUrl, e.getMessage());
                }
                // 等待后重试
                try {
                    Thread.sleep(1000 * (i + 1));
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        }
        return DownloadResult.failure(originalUrl, "重试次数耗尽");
    }

    private String uploadWithRetry(File file) {
        for (int i = 0; i < retryTimes; i++) {
            try {
                return uploadToStorage(file);
            } catch (Exception e) {
                log.warn("第{}次上传失败: {}, 错误: {}", i + 1, file.getName(), e.getMessage());
                if (i < retryTimes - 1) {
                    try {
                        Thread.sleep(1000 * (i + 1));
                    } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                        break;
                    }
                }
            }
        }
        return null;
    }
}
```

#### 7.2 工具节点处理流程

```java
@Service
public class ToolNodeProcessor {

    @Autowired
    private FileConversionService fileConversionService;

    /**
     * 处理工具节点执行结果
     */
    public void processToolNodeResult(ToolNodeResult nodeResult) {
        try {
            // 1. 更新节点状态为执行中
            updateNodeStatus(nodeResult.getNodeId(), NodeStatus.PROCESSING);

            // 2. 处理original_files转换为output_files
            if (CollectionUtils.isNotEmpty(nodeResult.getOriginalFiles())) {
                List<String> outputFiles = fileConversionService.convertFilesToStorage(
                    nodeResult.getOriginalFiles(),
                    nodeResult.getNodeId()
                );
                nodeResult.setOutputFiles(outputFiles);
            }

            // 3. 保存节点执行结果
            saveNodeResult(nodeResult);

            // 4. 更新节点状态为完成
            updateNodeStatus(nodeResult.getNodeId(), NodeStatus.COMPLETED);

            // 5. 如果需要预览，推送结果到前端
            if (nodeResult.isPreviewRequired()) {
                pushResultToFrontend(nodeResult);
            }

        } catch (Exception e) {
            log.error("处理工具节点结果失败: {}", nodeResult.getNodeId(), e);
            updateNodeStatus(nodeResult.getNodeId(), NodeStatus.FAILED);
            updateNodeError(nodeResult.getNodeId(), e.getMessage());
        }
    }
}
```

## API接口设计

### Java后端新增API

#### 1. 项目管理API
```java
@RestController
@RequestMapping("/api/ai/project")
public class AIProjectController {

    @PostMapping("/create")
    CommonResult<AIProject> createProject(@RequestBody CreateProjectParam param);

    @GetMapping("/list")
    CommonResult<List<AIProjectListResult>> getProjectList(@RequestParam Long memberId);

    @GetMapping("/{id}")
    CommonResult<AIProjectDetailResult> getProjectDetail(@PathVariable Long id);

    @DeleteMapping("/{id}")
    CommonResult<Void> deleteProject(@PathVariable Long id);
}
```

#### 2. AI任务API
```java
@RestController
@RequestMapping("/api/ai/task")
public class AITaskController {

    @PostMapping("/submit")
    CommonResult<AITask> submitTask(@RequestBody SubmitTaskParam param);

    @GetMapping("/{taskId}/status")
    CommonResult<TaskStatusResult> getTaskStatus(@PathVariable Long taskId);

    @GetMapping("/{taskId}/workflow")
    CommonResult<WorkflowStatusResult> getWorkflowStatus(@PathVariable Long taskId);

    @PostMapping("/{taskId}/stop")
    CommonResult<Void> stopTask(@PathVariable Long taskId);
}
```

### Python FastAPI接口

#### 1. 工作流API
```python
@router.post("/workflow/generate")
async def generate_workflow(request: WorkflowGenerateRequest) -> WorkflowResponse:
    """根据提示词生成工作流"""
    pass

@router.post("/workflow/execute")
async def execute_workflow(request: WorkflowExecuteRequest) -> TaskResponse:
    """执行工作流"""
    pass

@router.get("/workflow/{task_id}/status")
async def get_workflow_status(task_id: str) -> WorkflowStatusResponse:
    """获取工作流执行状态"""
    pass
```

#### 2. AI工具API
```python
@router.get("/tools/list")
async def list_tools() -> ToolListResponse:
    """获取可用工具列表"""
    pass

@router.post("/tools/{tool_uuid}/execute")
async def execute_tool(tool_uuid: str, request: ToolExecuteRequest) -> ToolResponse:
    """执行指定工具"""
    pass
```

## 实施优先级

### Phase 1: 基础架构 (3-4天)
1. 创建Python FastAPI项目基础结构
2. 数据库表设计和创建
3. Java后端API框架搭建
4. 基础的项目CRUD功能
5. **AI模型适配器架构实现**
   - 定义BaseAIAdapter抽象基类
   - 实现AIAdapterFactory工厂类
   - 配置管理系统设计
   - 适配器注册和发现机制

### Phase 2: 混合平台AI工具集成 (5-6天)

#### 第一阶段：核心架构实现 (Day 1-2)
1. **智能适配器选择器实现**
   - SmartAdapterSelector核心逻辑
   - 混合平台配置管理系统
   - 降级策略和健康检查机制
   - 性能监控和使用统计

2. **豆包适配器完善**
   - 基于异步任务模式的核心架构（✅ 已有图生视频）
   - 完善其余API接口实现
   - 统一的HTTP请求封装和错误处理

#### 第二阶段：多平台适配器实现 (Day 3-4)
1. **通义千问适配器** - 专精图像生成
   - TongYiAdapter基础实现
   - text_to_image优质实现（主力）
   - image_to_image优质实现（主力）
   - 其他接口基础实现（备用）

2. **文心一言适配器** - 专精音频处理
   - WenXinAdapter基础实现
   - generate_music优质实现（主力）
   - text_to_speech优质实现（主力）
   - 其他接口基础实现（备用）

3. **豆包适配器补全** - 专精视频生成
   - image_to_video优质实现（✅ 已完成）
   - text_to_video优质实现（✅ 已完成）
   - speech_to_subtitle优质实现（主力）
   - 文生图、图生图基础实现（备用）

#### 第三阶段：混合平台集成测试 (Day 5-6)
1. **混合工作流测试**
   - 图像生成（通义）→ 视频生成（豆包）→ 音频处理（文心）
   - 故障转移测试：主平台挂掉后自动切换备用平台
   - 成本优化测试：根据配置选择最经济的平台组合

2. **平台性能对比**
   - 各平台在不同任务上的质量对比
   - 成本效益分析和优化建议
   - 响应时间和稳定性测试

3. **配置管理和监控**
   - 热配置更新功能
   - 平台使用统计和分析
   - 告警和故障恢复机制

**Phase 2 的关键交付物：**
- ✅ 智能适配器选择系统
- ✅ 三大平台适配器（豆包、通义、文心）
- ✅ 混合平台配置管理
- ✅ 故障转移和性能监控
- ✅ 完整的混合工作流测试报告

**平台能力分工：**
```text
📸 图像任务  → 通义千问（主）+ 豆包（备）+ 文心（备）
🎬 视频任务  → 豆包（主）+ 通义（备）+ 文心（备）
🎵 音频任务  → 文心（主）+ 豆包（备）+ 通义（备）
```

### Phase 3: 工作流引擎 (4-5天)
1. LLM工作流生成逻辑
2. 工作流执行引擎
3. 状态管理和中断恢复
4. 参数传递和验证

### Phase 4: 前端重构 (3-4天)
1. 任务执行页面UI重构
2. WebSocket实时通信集成
3. 中间结果预览功能
4. 用户体验优化

### Phase 5: 集成测试 (2-3天)
1. 端到端流程测试
2. 错误处理测试
3. 性能优化
4. 生产环境部署

## 成功标准

### 基础功能标准
1. **功能完整性**：用户可以输入提示词和图片，系统自动生成完整视频
2. **实时反馈**：工作流执行过程中，前端能实时显示进度和中间结果
3. **稳定性**：系统在异常情况下能够恢复和继续执行
4. **性能**：单个任务处理时间在合理范围内（10-30分钟）
5. **用户体验**：界面友好，操作简单，错误提示清晰

### 混合平台集成标准
6. **平台智能选择**：系统能根据任务类型自动选择最佳AI平台
   - 文生图自动选择通义千问
   - 图生视频自动选择豆包
   - 音频处理自动选择文心一言
7. **故障自动转移**：主平台不可用时，自动切换到备用平台，成功率≥95%
8. **成本优化**：在保证质量前提下，平均成本比单一平台降低20-30%
9. **配置热更新**：支持不重启服务的平台配置更新
10. **性能监控**：实时监控各平台使用情况、成功率、响应时间

## 风险和挑战

1. **AI服务稳定性**：第三方AI API的可用性和响应时间
2. **文件处理性能**：大视频文件的上传下载和处理效率
3. **工作流复杂度**：动态生成的工作流可能过于复杂难以执行
4. **成本控制**：AI API调用费用的控制和优化
5. **并发处理**：多用户同时使用时的资源分配和性能保证

## 后续扩展

### 基础功能扩展
1. **模板库**：预定义常用的工作流模板
2. **批量处理**：支持批量上传和批量生成
3. **社区功能**：用户分享作品和模板
4. **API开放**：为第三方开发者提供API接口
5. **移动端支持**：开发移动端应用

### 混合平台扩展
6. **更多AI平台接入**：
   - 国际平台：OpenAI GPT-4, Claude, Midjourney, Runway
   - 国内平台：智谱AI, 百川智能, MiniMax
   - 开源模型：Stable Diffusion, LLaMA等本地部署
7. **智能成本控制**：
   - AI预算管理和用量限制
   - 实时成本监控和告警
   - 成本优化建议引擎
8. **平台性能优化**：
   - 负载均衡和并发控制
   - 缓存机制减少重复调用
   - 预测性故障检测
9. **企业级功能**：
   - 多租户平台配置隔离
   - 精细化权限控制
   - 审计日志和合规性支持

### 技术创新扩展
10. **AI模型自动评估**：根据任务结果自动调整平台选择策略
11. **混合推理**：同时调用多个平台对比结果，选择最佳输出
12. **边缘计算集成**：本地模型 + 云端模型混合部署