# AI视频生成工作流系统详细需求

## 项目背景

基于现有的mall电商系统，开发一个AI视频生成工作流系统，通过智能分析用户提示词和上传的图片，动态生成完整的视频制作工作流，并自动执行生成最终的短视频内容。

## 项目架构

### 现有项目结构
- **管理后端前端项目**：`/mnt/d/software/beilv-agent/mall/mall-admin-web`
- **管理后端后端项目**：`/mnt/d/software/beilv-agent/mall/mall/mall-admin`
- **用户端前端项目**：`/mnt/d/software/beilv-agent/mall/beilv-agent-web`
- **用户端后端项目**：`/mnt/d/software/beilv-agent/mall/mall/mall-portal`
- **智能体Python后端项目**：`/mnt/d/software/beilv-agent/mall/beilv-agent` (新建FastAPI项目)

### 技术栈
- **前端**：React + TypeScript + Ant Design
- **Java后端**：Spring Boot + MyBatis + MySQL
- **Python AI服务**：FastAPI + LangChain + Celery
- **数据库**：MySQL (共享)
- **文件存储**：MinIO/阿里云OSS
- **实时通信**：WebSocket

## 核心功能需求

### 1. AI工具注册系统

Python后端通过LangChain注册支持的工具，每个工具函数都需要有唯一且固定的UUID，便于数据库记录后，后端程序通过UUID定位对应的函数。

#### 1.1 工具列表 (10个AI工具)
1. **文生图** (第三方API) - UUID: `tool-text2img-001`
2. **图生图** (第三方API) - UUID: `tool-img2img-002`
3. **图生视频** (第三方API) - UUID: `tool-img2video-003`
4. **文生视频** (第三方API) - UUID: `tool-text2video-004`
5. **背景音乐生成** (第三方API) - UUID: `tool-music-gen-005`
6. **文案转语音** (第三方API) - UUID: `tool-text2speech-008`
7. **语音生成字幕** (第三方API) - UUID: `tool-speech2sub-009`
8. **视频合并** (本地接口) - UUID: `tool-video-merge-010`
9. **音视频合并** (本地接口) - UUID: `tool-av-merge-011`
10. **字幕视频合并** (本地接口) - UUID: `tool-sub-merge-012`

**说明**：图片理解、生成图片提示词、生成视频提示词、口播文案生成功能已整合到工作流生成阶段，由LLM在分析用户输入时一次性完成。

#### 1.2 AI模型适配器架构设计

为了支持后续切换不同的AI模型提供商（如豆包、通义千问、文心一言等），采用适配器模式设计AI模型接入层。

##### 1.2.1 混合平台适配器架构
```
AI工具层 (tool-text2img-001, tool-img2video-003...)
       ↓
智能适配器选择器 (SmartAdapterSelector)
       ↓
AI模型适配器层 (DouBao, TongYi, WenXin, OpenAI...)
       ↓
AI模型提供商层 (各平台API调用)
```

**核心理念**：各取所长，混合使用不同AI平台的优势能力
- 📸 **图像生成** - 通义千问 (图片质量佳)
- 🎬 **视频生成** - 豆包 (视频效果好)
- 🎵 **音频处理** - 文心一言 (音频技术强)
- 💰 **成本控制** - 根据价格选择最优平台
- 🌍 **地域适配** - 不同地区使用不同平台

##### 1.2.2 按工具功能的适配器接口设计
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

@dataclass
class AIModelResult:
    """AI模型调用结果"""
    success: bool
    data: Optional[Dict[str, Any]] = None
    files: Optional[List[str]] = None  # 生成的文件URL列表
    error_message: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None  # 模型返回的元数据

# ===== 按工具功能分别定义适配器基类 =====

class BaseT2IAdapter(ABC):
    """文生图适配器基类"""

    @abstractmethod
    def text_to_image(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """文生图接口"""
        pass

class BaseI2IAdapter(ABC):
    """图生图适配器基类"""

    @abstractmethod
    def image_to_image(self, prompt: str, source_image: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """图生图接口"""
        pass

class BaseI2VAdapter(ABC):
    """图生视频适配器基类"""

    @abstractmethod
    def image_to_video(self, prompt: str, source_image: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """图生视频接口"""
        pass

class BaseT2VAdapter(ABC):
    """文生视频适配器基类"""

    @abstractmethod
    def text_to_video(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """文生视频接口"""
        pass

class BaseMusicGenAdapter(ABC):
    """音乐生成适配器基类"""

    @abstractmethod
    def generate_music(self, prompt: str, **kwargs) -> AIModelResult:
        """音乐生成接口"""
        pass

class BaseTTS_Adapter(ABC):
    """文本转语音适配器基类"""

    @abstractmethod
    def text_to_speech(self, text: str, voice_id: str, **kwargs) -> AIModelResult:
        """文本转语音接口"""
        pass

class BaseASR_Adapter(ABC):
    """语音转字幕适配器基类"""

    @abstractmethod
    def speech_to_subtitle(self, audio_url: str, language: str, **kwargs) -> AIModelResult:
        """语音转字幕接口"""
        pass

# ===== 工具适配器工厂类 =====

class ToolAdapterFactory:
    """工具适配器工厂类"""

    _adapters = {
        "text_to_image": {},      # 存储文生图适配器
        "image_to_image": {},     # 存储图生图适配器
        "image_to_video": {},     # 存储图生视频适配器
        "text_to_video": {},      # 存储文生视频适配器
        "generate_music": {},     # 存储音乐生成适配器
        "text_to_speech": {},     # 存储语音合成适配器
        "speech_to_subtitle": {}  # 存储语音识别适配器
    }

    @classmethod
    def register_adapter(cls, tool_type: str, platform: str, adapter_class):
        """注册工具适配器"""
        if tool_type not in cls._adapters:
            raise ValueError(f"Unknown tool type: {tool_type}")
        cls._adapters[tool_type][platform] = adapter_class

    @classmethod
    def create_adapter(cls, tool_type: str, platform: str, config: Dict[str, Any]):
        """创建工具适配器实例"""
        if tool_type not in cls._adapters:
            raise ValueError(f"Unknown tool type: {tool_type}")

        if platform not in cls._adapters[tool_type]:
            raise ValueError(f"Platform {platform} not available for {tool_type}")

        adapter_class = cls._adapters[tool_type][platform]
        return adapter_class(config)

    @classmethod
    def list_platforms(cls, tool_type: str) -> List[str]:
        """列出指定工具类型的可用平台"""
        if tool_type not in cls._adapters:
            return []
        return list(cls._adapters[tool_type].keys())

    @classmethod
    def list_all_capabilities(cls) -> Dict[str, List[str]]:
        """列出所有工具类型及其可用平台"""
        return {
            tool_type: list(platforms.keys())
            for tool_type, platforms in cls._adapters.items()
        }
```

##### 1.2.3 按工具功能的适配器实现示例

```python
import requests
import time
from typing import Dict, Any, Optional

# ===== 豆包基础连接类 =====
class DouBaoBase:
    """豆包基础连接类"""

    def __init__(self, config: Dict[str, Any]):
        self.api_key = config.get("api_key")
        self.base_url = config.get("base_url", "https://ark.cn-beijing.volces.com")
        self.default_model = config.get("default_model", "doubao-seedance-1-0-pro-250528")
        self.timeout = config.get("timeout", 60)
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

    def _make_request(self, endpoint: str, payload: Dict = None, method: str = "POST") -> Dict:
        """发起HTTP请求的通用方法"""
        url = f"{self.base_url}{endpoint}"

        try:
            if method == "POST":
                response = requests.post(url, json=payload, headers=self.headers, timeout=self.timeout)
            elif method == "GET":
                response = requests.get(url, headers=self.headers, timeout=self.timeout)
            else:
                raise ValueError(f"不支持的HTTP方法: {method}")

            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            return {"success": False, "message": str(e)}

    def _poll_task_status(self, task_id: str, max_attempts: int = 60, interval: int = 10) -> Dict[str, Any]:
        """轮询任务状态直到完成"""
        for attempt in range(max_attempts):
            try:
                status_response = self._make_request(f"/api/v3/contents/generations/tasks/{task_id}", method="GET")

                if not status_response:
                    continue

                status = status_response.get("status")

                if status == "completed":
                    files = []
                    if "result" in status_response and "videos" in status_response["result"]:
                        files = [video["url"] for video in status_response["result"]["videos"]]
                    elif "result" in status_response and "images" in status_response["result"]:
                        files = [img["url"] for img in status_response["result"]["images"]]

                    return {"success": True, "files": files, "data": status_response}
                elif status == "failed":
                    error_msg = status_response.get("error", {}).get("message", "任务失败")
                    return {"success": False, "error_message": error_msg}
                elif status in ["pending", "processing"]:
                    time.sleep(interval)
                    continue
                else:
                    time.sleep(interval)
                    continue

            except Exception as e:
                if attempt == max_attempts - 1:
                    return {"success": False, "error_message": f"轮询任务状态失败: {str(e)}"}
                time.sleep(interval)

        return {"success": False, "error_message": f"任务超时，最大等待时间: {max_attempts * interval}秒"}

# ===== 豆包图生视频适配器（专业实现）=====
class DouBaoI2VAdapter(BaseI2VAdapter, DouBaoBase):
    """豆包图生视频适配器 - 专业实现"""

    def image_to_video(self, prompt: str, source_image: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包图生视频专业实现"""
        try:
            content = [
                {
                    "type": "text",
                    "text": self._build_video_prompt(prompt, aspect_ratio, **kwargs)
                },
                {
                    "type": "image_url",
                    "image_url": {"url": source_image}
                }
            ]

            payload = {
                "model": kwargs.get("model", self.default_model),
                "content": content
            }

            task_response = self._make_request("/api/v3/contents/generations/tasks", payload, method="POST")

            if not task_response.get("success") or "id" not in task_response:
                return AIModelResult(
                    success=False,
                    error_message=task_response.get("message", "创建任务失败")
                )

            video_result = self._poll_task_status(task_response["id"])

            if video_result["success"]:
                return AIModelResult(
                    success=True,
                    files=video_result["files"],
                    data=video_result["data"],
                    metadata={
                        "platform": "doubao",
                        "tool_type": "image_to_video",
                        "model": self.default_model,
                        "task_id": task_response["id"]
                    }
                )
            else:
                return AIModelResult(success=False, error_message=video_result["error_message"])

        except Exception as e:
            return AIModelResult(success=False, error_message=str(e))

    def _build_video_prompt(self, prompt: str, aspect_ratio: str, **kwargs) -> str:
        """构建豆包视频生成提示词"""
        video_prompt = prompt

        resolution_map = {
            "16:9": "1080p", "9:16": "720p", "1:1": "720p", "4:3": "720p"
        }
        resolution = resolution_map.get(aspect_ratio, "1080p")
        video_prompt += f" --resolution {resolution}"

        duration = kwargs.get("duration", 5)
        video_prompt += f" --duration {duration}"

        camera_fixed = kwargs.get("camera_fixed", False)
        video_prompt += f" --camerafixed {str(camera_fixed).lower()}"

        watermark = kwargs.get("watermark", True)
        video_prompt += f" --watermark {str(watermark).lower()}"

        return video_prompt

# ===== 豆包文生视频适配器（专业实现）=====
class DouBaoT2VAdapter(BaseT2VAdapter, DouBaoBase):
    """豆包文生视频适配器 - 专业实现"""

    def text_to_video(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包文生视频专业实现"""
        try:
            content = [{"type": "text", "text": self._build_video_prompt(prompt, aspect_ratio, **kwargs)}]
            payload = {"model": kwargs.get("model", self.default_model), "content": content}

            task_response = self._make_request("/api/v3/contents/generations/tasks", payload, method="POST")

            if not task_response.get("success") or "id" not in task_response:
                return AIModelResult(success=False, error_message=task_response.get("message", "创建任务失败"))

            video_result = self._poll_task_status(task_response["id"])

            if video_result["success"]:
                return AIModelResult(
                    success=True,
                    files=video_result["files"],
                    data=video_result["data"],
                    metadata={
                        "platform": "doubao",
                        "tool_type": "text_to_video",
                        "model": self.default_model,
                        "task_id": task_response["id"]
                    }
                )
            else:
                return AIModelResult(success=False, error_message=video_result["error_message"])

        except Exception as e:
            return AIModelResult(success=False, error_message=str(e))

    def _build_video_prompt(self, prompt: str, aspect_ratio: str, **kwargs) -> str:
        """构建视频提示词（与I2V共享逻辑）"""
        return DouBaoI2VAdapter._build_video_prompt(self, prompt, aspect_ratio, **kwargs)

# ===== 豆包其他工具适配器（基础实现，作为备用）=====
class DouBaoT2IAdapter(BaseT2IAdapter, DouBaoBase):
    """豆包文生图适配器 - 基础实现（备用）"""

    def text_to_image(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包文生图基础实现"""
        # TODO: 实现豆包文生图API
        return AIModelResult(success=False, error_message="豆包文生图接口待实现")

class DouBaoASRAdapter(BaseASR_Adapter, DouBaoBase):
    """豆包语音识别适配器 - 专业实现"""

    def speech_to_subtitle(self, audio_url: str, language: str, **kwargs) -> AIModelResult:
        """豆包语音识别专业实现"""
        # TODO: 实现豆包ASR API
        return AIModelResult(success=False, error_message="豆包ASR接口待实现")

# ===== 适配器注册示例 =====
def register_doubao_adapters():
    """注册豆包的所有工具适配器"""
    # 豆包的强项：视频生成
    ToolAdapterFactory.register_adapter("image_to_video", "doubao", DouBaoI2VAdapter)
    ToolAdapterFactory.register_adapter("text_to_video", "doubao", DouBaoT2VAdapter)
    ToolAdapterFactory.register_adapter("speech_to_subtitle", "doubao", DouBaoASRAdapter)

    # 豆包的备用功能
    ToolAdapterFactory.register_adapter("text_to_image", "doubao", DouBaoT2IAdapter)

# 通义千问适配器注册示例（专精图像生成）
def register_tongyi_adapters():
    """注册通义千问的工具适配器"""
    # 通义的强项：图像生成
    ToolAdapterFactory.register_adapter("text_to_image", "tongyi", TongYiT2IAdapter)
    ToolAdapterFactory.register_adapter("image_to_image", "tongyi", TongYiI2IAdapter)

    # 通义的备用功能
    ToolAdapterFactory.register_adapter("image_to_video", "tongyi", TongYiI2VAdapter)

# 文心一言适配器注册示例（专精音频处理）
def register_wenxin_adapters():
    """注册文心一言的工具适配器"""
    # 文心的强项：音频处理
    ToolAdapterFactory.register_adapter("generate_music", "wenxin", WenXinMusicAdapter)
    ToolAdapterFactory.register_adapter("text_to_speech", "wenxin", WenXinTTSAdapter)

    # 文心的备用功能
    ToolAdapterFactory.register_adapter("text_to_image", "wenxin", WenXinT2IAdapter)
```

##### 1.2.4 按工具功能的配置管理
```yaml
# config/tool_adapters.yaml
platforms:
  doubao:
    config:
      api_key: "${DOUBAO_API_KEY}"
      base_url: "https://ark.cn-beijing.volces.com"
      default_model: "doubao-seedance-1-0-pro-250528"
      timeout: 60
    capabilities:
      strong_tools: ["image_to_video", "text_to_video", "speech_to_subtitle"]
      backup_tools: ["text_to_image"]
      cost_level: "medium"
      quality_scores:
        image_to_video: 9.0
        text_to_video: 9.0
        speech_to_subtitle: 8.5
        text_to_image: 6.5

  tongyi:
    config:
      api_key: "${TONGYI_API_KEY}"
      base_url: "https://dashscope.aliyuncs.com"
      timeout: 30
    capabilities:
      strong_tools: ["text_to_image", "image_to_image"]
      backup_tools: ["image_to_video", "text_to_video"]
      cost_level: "low"
      quality_scores:
        text_to_image: 9.5
        image_to_image: 9.0
        image_to_video: 7.0

  wenxin:
    config:
      api_key: "${WENXIN_API_KEY}"
      base_url: "https://aip.baidubce.com"
      timeout: 45
    capabilities:
      strong_tools: ["generate_music", "text_to_speech"]
      backup_tools: ["text_to_image"]
      cost_level: "low"
      quality_scores:
        generate_music: 8.5
        text_to_speech: 8.8
        text_to_image: 6.0

# 工具选择策略
tool_strategy:
  primary_platforms:
    text_to_image: "tongyi"        # 通义质量最好
    image_to_image: "tongyi"       # 通义专业
    image_to_video: "doubao"       # 豆包专业
    text_to_video: "doubao"        # 豆包专业
    generate_music: "wenxin"       # 文心专业
    text_to_speech: "wenxin"       # 文心专业
    speech_to_subtitle: "doubao"   # 豆包专业

  fallback_platforms:
    text_to_image: ["doubao", "wenxin"]
    image_to_image: ["doubao", "wenxin"]
    image_to_video: ["tongyi", "wenxin"]
    text_to_video: ["tongyi", "wenxin"]
    generate_music: ["doubao", "tongyi"]
    text_to_speech: ["doubao", "tongyi"]
    speech_to_subtitle: ["tongyi", "wenxin"]
```

##### 1.2.5 按工具功能的智能选择器
```python
class ToolAdapterSelector:
    """按工具功能的智能适配器选择器"""

    def __init__(self, config):
        self.config = config
        self.strategy = config["tool_strategy"]
        self.factory = ToolAdapterFactory()
        self.performance_tracker = ToolPerformanceTracker()

    def get_best_adapter(self, tool_type: str, context: Dict = None):
        """为特定工具选择最佳适配器"""
        # 1. 获取首选平台
        primary_platform = self.strategy["primary_platforms"].get(tool_type)

        # 2. 检查首选平台是否可用
        if primary_platform and self._is_platform_available(tool_type, primary_platform):
            adapter = self.factory.create_adapter(tool_type, primary_platform,
                                                  self.config["platforms"][primary_platform]["config"])
            self._log_usage(tool_type, primary_platform, "primary")
            return adapter

        # 3. 使用降级策略
        fallback_platforms = self.strategy["fallback_platforms"].get(tool_type, [])
        for platform in fallback_platforms:
            if self._is_platform_available(tool_type, platform):
                adapter = self.factory.create_adapter(tool_type, platform,
                                                      self.config["platforms"][platform]["config"])
                self._log_usage(tool_type, platform, "fallback")
                return adapter

        # 4. 没有找到可用的平台
        available_platforms = self.factory.list_platforms(tool_type)
        raise Exception(f"工具 {tool_type} 没有可用的平台。可用平台: {available_platforms}")

    def _is_platform_available(self, tool_type: str, platform: str) -> bool:
        """检查平台对指定工具是否可用"""
        try:
            # 检查平台是否支持该工具
            if platform not in self.factory.list_platforms(tool_type):
                return False

            # 检查平台配置和质量要求
            platform_config = self.config["platforms"].get(platform, {})
            capabilities = platform_config.get("capabilities", {})

            # 检查质量分数
            quality_scores = capabilities.get("quality_scores", {})
            tool_quality = quality_scores.get(tool_type, 0)

            # 质量太低则不使用
            if tool_quality < 6.0:
                return False

            return self._health_check(platform)

        except Exception:
            return False

    def _health_check(self, platform: str) -> bool:
        """平台健康检查"""
        # TODO: 实现平台连通性检查
        return True

    def _log_usage(self, tool_type: str, platform: str, usage_type: str):
        """记录使用情况"""
        self.performance_tracker.record_usage(tool_type, platform, usage_type)

class AIToolExecutor:
    """按工具功能的AI工具执行器"""

    def __init__(self):
        self.config = load_config("tool_adapters.yaml")
        self.selector = ToolAdapterSelector(self.config)

    def execute_text2img_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行文生图工具 - 自动选择最佳平台（默认通义千问）"""
        adapter = self.selector.get_best_adapter("text_to_image")

        result = adapter.text_to_image(
            prompt=tool_request["input_data"]["prompt"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "text_to_image")

    def execute_img2video_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行图生视频工具 - 自动选择最佳平台（默认豆包）"""
        adapter = self.selector.get_best_adapter("image_to_video")

        result = adapter.image_to_video(
            prompt=tool_request["input_data"]["prompt"],
            source_image=tool_request["input_data"]["source_image_url"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "image_to_video")

    def execute_music_gen_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行音乐生成工具 - 自动选择最佳平台（默认文心）"""
        adapter = self.selector.get_best_adapter("generate_music")

        result = adapter.generate_music(
            prompt=tool_request["input_data"]["prompt"]
        )

        return self._format_result(result, "generate_music")

    def _format_result(self, result: AIModelResult, tool_type: str) -> Dict[str, Any]:
        """格式化结果"""
        if result.success:
            return {
                "success": True,
                "output_data": result.data,
                "original_files": result.files,
                "metadata": {
                    **result.metadata,
                    "tool_type": tool_type,
                    "selected_platform": result.metadata.get("platform", "unknown")
                }
            }
        else:
            return {
                "success": False,
                "error_message": result.error_message
            }
```

##### 1.2.6 模型切换策略

**动态模型切换**：
```python
class AdapterSwitchStrategy:
    """适配器切换策略"""

    def __init__(self):
        self.performance_metrics = {}  # 性能指标记录
        self.cost_metrics = {}         # 成本指标记录
        self.failure_counts = {}       # 失败计数

    def should_switch_adapter(self, current_adapter: str, tool_type: str) -> Optional[str]:
        """判断是否应该切换适配器"""
        # 基于失败率切换
        if self.failure_counts.get(current_adapter, 0) > 3:
            return self._get_backup_adapter(current_adapter, tool_type)

        # 基于性能切换
        if self._is_performance_degraded(current_adapter, tool_type):
            return self._get_better_performance_adapter(tool_type)

        return None

    def _get_backup_adapter(self, failed_adapter: str, tool_type: str) -> str:
        """获取备用适配器"""
        backup_map = {
            "doubao": "tongyi",
            "tongyi": "wenxin",
            "wenxin": "doubao"
        }
        return backup_map.get(failed_adapter, "doubao")
```

**配置热更新**：
```python
class AdapterConfigManager:
    """适配器配置管理器"""

    def __init__(self):
        self.config_file = "tool_adapters.yaml"
        self.config_cache = {}
        self.last_modified = 0

    def get_current_config(self) -> Dict[str, Any]:
        """获取当前配置（支持热更新）"""
        current_modified = os.path.getmtime(self.config_file)
        if current_modified > self.last_modified:
            self.config_cache = self._load_config()
            self.last_modified = current_modified
        return self.config_cache

    def switch_default_adapter(self, tool_type: str, new_adapter: str):
        """切换默认适配器"""
        config = self.get_current_config()
        config[f"default_{tool_type}_adapter"] = new_adapter
        self._save_config(config)
```

##### 1.2.7 工具规范
- 每个工具必须有标准的输入输出格式
- 支持JSON Schema定义参数结构
- 统一的错误处理和状态报告
- 文件输入输出自动管理
- 支持多AI模型切换的适配器模式
- 配置驱动的模型选择机制
- 支持运行时动态切换和故障转移
- 性能监控和成本控制机制

#### 1.3 工具节点（结构）
        """构建豆包视频生成提示词"""
        # 基础提示词
        video_prompt = prompt

        # 添加分辨率参数
        resolution = self._convert_aspect_ratio_to_resolution(aspect_ratio)
        video_prompt += f" --resolution {resolution}"

        # 添加时长参数
        duration = kwargs.get("duration", 5)
        video_prompt += f" --duration {duration}"

        # 添加相机运动参数
        camera_fixed = kwargs.get("camera_fixed", False)
        video_prompt += f" --camerafixed {str(camera_fixed).lower()}"

        # 添加水印参数
        watermark = kwargs.get("watermark", True)
        video_prompt += f" --watermark {str(watermark).lower()}"

        return video_prompt

    def _convert_aspect_ratio_to_resolution(self, aspect_ratio: str) -> str:
        """转换宽高比为豆包分辨率格式"""
        ratio_map = {
            "16:9": "1080p",  # 1920x1080
            "9:16": "720p",   # 720x1280 (竖屏)
            "1:1": "720p",    # 720x720 (方形)
            "4:3": "720p"     # 960x720
        }
        return ratio_map.get(aspect_ratio, "1080p")

    def _poll_task_status(self, task_id: str, max_attempts: int = 60, interval: int = 10) -> Dict[str, Any]:
        """轮询任务状态直到完成"""
        for attempt in range(max_attempts):
            try:
                # 查询任务状态
                status_response = self._make_request(f"/api/v3/contents/generations/tasks/{task_id}", method="GET")

                if not status_response:
                    continue

                status = status_response.get("status")

                if status == "completed":
                    # 任务完成，提取视频URL
                    files = []
                    if "result" in status_response and "videos" in status_response["result"]:
                        files = [video["url"] for video in status_response["result"]["videos"]]

                    return {
                        "success": True,
                        "files": files,
                        "data": status_response
                    }
                elif status == "failed":
                    # 任务失败
                    error_msg = status_response.get("error", {}).get("message", "视频生成失败")
                    return {
                        "success": False,
                        "error_message": error_msg
                    }
                elif status in ["pending", "processing"]:
                    # 任务进行中，继续等待
                    time.sleep(interval)
                    continue
                else:
                    # 未知状态
                    time.sleep(interval)
                    continue

            except Exception as e:
                if attempt == max_attempts - 1:
                    return {
                        "success": False,
                        "error_message": f"轮询任务状态失败: {str(e)}"
                    }
                time.sleep(interval)

        # 超时
        return {
            "success": False,
            "error_message": f"任务超时，最大等待时间: {max_attempts * interval}秒"
        }

    def _make_request(self, endpoint: str, payload: Dict = None, method: str = "POST") -> Dict:
        """发起HTTP请求的通用方法"""
        url = f"{self.base_url}{endpoint}"

        try:
            if method == "POST":
                response = requests.post(
                    url,
                    json=payload,
                    headers=self.headers,
                    timeout=self.timeout
                )
            elif method == "GET":
                response = requests.get(
                    url,
                    headers=self.headers,
                    timeout=self.timeout
                )
            else:
                raise ValueError(f"不支持的HTTP方法: {method}")

            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            return {
                "success": False,
                "message": str(e)
            }

    def text_to_image(self, prompt: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包文生图实现（需要实现具体的API接口）"""
        # TODO: 根据豆包文生图API实现
        pass

    def image_to_image(self, prompt: str, source_image: str, aspect_ratio: str, **kwargs) -> AIModelResult:
        """豆包图生图实现（需要实现具体的API接口）"""
        # TODO: 根据豆包图生图API实现
        pass

    def generate_music(self, prompt: str, **kwargs) -> AIModelResult:
        """豆包音乐生成实现（需要实现具体的API接口）"""
        # TODO: 根据豆包音乐生成API实现
        pass

    def text_to_speech(self, text: str, voice_id: str, **kwargs) -> AIModelResult:
        """豆包文本转语音实现（需要实现具体的API接口）"""
        # TODO: 根据豆包TTS API实现
        pass

    def speech_to_subtitle(self, audio_url: str, language: str, **kwargs) -> AIModelResult:
        """豆包语音转字幕实现（需要实现具体的API接口）"""
        # TODO: 根据豆包ASR API实现
        pass

# 注册豆包适配器
AIAdapterFactory.register_adapter("doubao", DouBaoAdapter)
```

##### 1.2.4 豆包API接口扩展计划

基于当前的图生视频接口实现模式，其他豆包API接口需要按照类似的异步任务模式实现：

**1. 文生图接口**
- 预计使用相同的任务创建和轮询模式
- endpoint: `/api/v3/contents/generations/tasks`
- 模型参数需要调整为图像生成模型

**2. 图生图接口**
- 与图生视频类似，需要在content中包含source_image
- 使用相同的任务管理API

**3. 音乐生成接口**
- 可能使用独立的音频生成API端点
- 需要支持音乐风格、时长等参数

**4. 文本转语音接口**
- 可能支持实时或近实时转换
- 需要支持不同的声音ID选择

**5. 语音转字幕接口**
- 需要上传音频文件
- 支持多语言识别
```

##### 1.2.4 混合平台配置管理
```yaml
# config/ai_adapters.yaml
adapters:
  doubao:
    class: "adapters.doubao.DouBaoAdapter"
    config:
      api_key: "${DOUBAO_API_KEY}"
      base_url: "https://ark.cn-beijing.volces.com"
      default_model: "doubao-seedance-1-0-pro-250528"
      timeout: 60
    capabilities:
      strengths: ["image_to_video", "text_to_video", "speech_to_subtitle"]
      cost_level: "medium"
      quality_score: 8.5

  tongyi:
    class: "adapters.tongyi.TongYiAdapter"
    config:
      api_key: "${TONGYI_API_KEY}"
      base_url: "https://dashscope.aliyuncs.com"
      default_model: "wanx-v1"
      timeout: 30
    capabilities:
      strengths: ["text_to_image", "image_to_image"]
      cost_level: "low"
      quality_score: 9.0

  wenxin:
    class: "adapters.wenxin.WenXinAdapter"
    config:
      api_key: "${WENXIN_API_KEY}"
      base_url: "https://aip.baidubce.com"
      timeout: 45
    capabilities:
      strengths: ["generate_music", "text_to_speech"]
      cost_level: "low"
      quality_score: 8.0

# 按功能分配最佳平台策略
platform_strategy:
  default_adapters:
    text_to_image: "tongyi"        # 文生图用通义（质量好）
    image_to_image: "tongyi"       # 图生图用通义
    image_to_video: "doubao"       # 图生视频用豆包（效果佳）
    text_to_video: "doubao"        # 文生视频用豆包
    generate_music: "wenxin"       # 音乐生成用文心（成本低）
    text_to_speech: "wenxin"       # 语音合成用文心
    speech_to_subtitle: "doubao"   # 语音识别用豆包

  # 降级策略：主平台不可用时的备选
  fallback_adapters:
    text_to_image: ["doubao", "wenxin"]
    image_to_image: ["doubao", "wenxin"]
    image_to_video: ["tongyi", "wenxin"]
    text_to_video: ["tongyi", "wenxin"]
    generate_music: ["doubao", "tongyi"]
    text_to_speech: ["doubao", "tongyi"]
    speech_to_subtitle: ["tongyi", "wenxin"]

  # 成本优化策略
  cost_optimization:
    enabled: true
    prefer_low_cost: true          # 优先使用低成本平台
    quality_threshold: 7.0         # 质量阈值，低于此分数不使用

  # 地域策略
  region_strategy:
    china:
      preferred: ["tongyi", "wenxin", "doubao"]
    international:
      preferred: ["openai", "claude"]
```

##### 1.2.5 按工具功能的智能选择器
```python
class ToolAdapterSelector:
    """按工具功能的智能适配器选择器"""

    def __init__(self, config):
        self.config = config
        self.strategy = config["tool_strategy"]
        self.factory = ToolAdapterFactory()
        self.performance_tracker = ToolPerformanceTracker()

    def get_best_adapter(self, tool_type: str, context: Dict = None):
        """为特定工具选择最佳适配器"""
        # 1. 获取首选平台
        primary_platform = self.strategy["primary_platforms"].get(tool_type)

        # 2. 检查首选平台是否可用
        if primary_platform and self._is_platform_available(tool_type, primary_platform):
            adapter = self.factory.create_adapter(tool_type, primary_platform,
                                                  self.config["platforms"][primary_platform]["config"])
            self._log_usage(tool_type, primary_platform, "primary")
            return adapter

        # 3. 使用降级策略
        fallback_platforms = self.strategy["fallback_platforms"].get(tool_type, [])
        for platform in fallback_platforms:
            if self._is_platform_available(tool_type, platform):
                adapter = self.factory.create_adapter(tool_type, platform,
                                                      self.config["platforms"][platform]["config"])
                self._log_usage(tool_type, platform, "fallback")
                return adapter

        # 4. 没有找到可用的平台
        available_platforms = self.factory.list_platforms(tool_type)
        raise Exception(f"工具 {tool_type} 没有可用的平台。可用平台: {available_platforms}")

    def _is_platform_available(self, tool_type: str, platform: str) -> bool:
        """检查平台对指定工具是否可用"""
        try:
            # 检查平台是否支持该工具
            if platform not in self.factory.list_platforms(tool_type):
                return False

            # 检查平台配置和质量要求
            platform_config = self.config["platforms"].get(platform, {})
            capabilities = platform_config.get("capabilities", {})

            # 检查质量分数
            quality_scores = capabilities.get("quality_scores", {})
            tool_quality = quality_scores.get(tool_type, 0)

            # 质量太低则不使用
            if tool_quality < 6.0:
                return False

            return self._health_check(platform)

        except Exception:
            return False

    def _health_check(self, platform: str) -> bool:
        """平台健康检查"""
        # TODO: 实现平台连通性检查
        return True

    def _log_usage(self, tool_type: str, platform: str, usage_type: str):
        """记录使用情况"""
        self.performance_tracker.record_usage(tool_type, platform, usage_type)

class AIToolExecutor:
    """按工具功能的AI工具执行器"""

    def __init__(self):
        self.config = load_config("tool_adapters.yaml")
        self.selector = ToolAdapterSelector(self.config)

    def execute_text2img_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行文生图工具 - 自动选择最佳平台（默认通义千问）"""
        adapter = self.selector.get_best_adapter("text_to_image")

        result = adapter.text_to_image(
            prompt=tool_request["input_data"]["prompt"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "text_to_image")

    def execute_img2video_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行图生视频工具 - 自动选择最佳平台（默认豆包）"""
        adapter = self.selector.get_best_adapter("image_to_video")

        result = adapter.image_to_video(
            prompt=tool_request["input_data"]["prompt"],
            source_image=tool_request["input_data"]["source_image_url"],
            aspect_ratio=tool_request["input_data"]["aspect_ratio"]
        )

        return self._format_result(result, "image_to_video")

    def execute_music_gen_tool(self, tool_request: Dict[str, Any]) -> Dict[str, Any]:
        """执行音乐生成工具 - 自动选择最佳平台（默认文心）"""
        adapter = self.selector.get_best_adapter("generate_music")

        result = adapter.generate_music(
            prompt=tool_request["input_data"]["prompt"]
        )

        return self._format_result(result, "generate_music")

    def _format_result(self, result: AIModelResult, tool_type: str) -> Dict[str, Any]:
        """格式化结果"""
        if result.success:
            return {
                "success": True,
                "output_data": result.data,
                "original_files": result.files,
                "metadata": {
                    **result.metadata,
                    "tool_type": tool_type,
                    "selected_platform": result.metadata.get("platform", "unknown")
                }
            }
        else:
            return {
                "success": False,
                "error_message": result.error_message
            }



##### 1.2.6 模型切换策略

**动态模型切换**：
```python
class AdapterSwitchStrategy:
    """适配器切换策略"""

    def __init__(self):
        self.performance_metrics = {}  # 性能指标记录
        self.cost_metrics = {}         # 成本指标记录
        self.failure_counts = {}       # 失败计数

    def should_switch_adapter(self, current_adapter: str, tool_type: str) -> Optional[str]:
        """判断是否应该切换适配器"""
        # 基于失败率切换
        if self.failure_counts.get(current_adapter, 0) > 3:
            return self._get_backup_adapter(current_adapter, tool_type)

        # 基于性能切换
        if self._is_performance_degraded(current_adapter, tool_type):
            return self._get_better_performance_adapter(tool_type)

        return None

    def _get_backup_adapter(self, failed_adapter: str, tool_type: str) -> str:
        """获取备用适配器"""
        backup_map = {
            "doubao": "tongyi",
            "tongyi": "wenxin",
            "wenxin": "doubao"
        }
        return backup_map.get(failed_adapter, "doubao")
```

**配置热更新**：
```python
class AdapterConfigManager:
    """适配器配置管理器"""

    def __init__(self):
        self.config_file = "ai_adapters.yaml"
        self.config_cache = {}
        self.last_modified = 0

    def get_current_config(self) -> Dict[str, Any]:
        """获取当前配置（支持热更新）"""
        current_modified = os.path.getmtime(self.config_file)
        if current_modified > self.last_modified:
            self.config_cache = self._load_config()
            self.last_modified = current_modified
        return self.config_cache

    def switch_default_adapter(self, tool_type: str, new_adapter: str):
        """切换默认适配器"""
        config = self.get_current_config()
        config[f"default_{tool_type}_adapter"] = new_adapter
        self._save_config(config)
```

##### 1.2.7 工具规范
- 每个工具必须有标准的输入输出格式
- 支持JSON Schema定义参数结构
- 统一的错误处理和状态报告
- 文件输入输出自动管理
- 支持多AI模型切换的适配器模式
- 配置驱动的模型选择机制
- 支持运行时动态切换和故障转移
- 性能监控和成本控制机制

#### 1.2 工具节点（结构）

每个工具节点的通用结构包含以下一级字段：

```json
{
  "id": "number",                   // 数据库主键ID
  "node_id": "string",              // 节点唯一ID，格式：node_{uuid}
  "tool_uuid": "string",            // 工具UUID，固定值如tool-img-understand-001
  "tool_name": "string",            // 工具名称，如"图片理解"
  "step_index": "number",           // 执行步骤索引，从0开始递增
  "status": "number",               // 节点状态：0-待执行，1-执行中，2-已完成，3-失败
  "input_data": "object",           // 输入数据对象（结构根据工具类型而定）
  "output_data": "object",          // 输出数据对象（结构根据工具类型而定）
  "output_files": "array",          // 输出文件列表（项目存储objectName）
  "original_files": "array",        // 原始文件列表（第三方API返回链接）
  "preview_required": "boolean",    // 是否需要前端预览
  "error_message": "string",        // 错误信息详情
  "create_time": "string",          // 节点创建时间
  "update_time": "string",          // 节点更新时间
  "start_time": "string",           // 开始执行时间
  "end_time": "string",             // 执行完成时间
  "duration_ms": "number",          // 执行耗时（毫秒）
  "creator_id": "number",           // 创建者用户ID
  "workflow_id": "string",          // 所属工作流ID
  "parent_node_id": "string",       // 父节点ID（用于构建执行链）
  "child_node_ids": "array",        // 子节点ID列表
  "sort_order": "number",           // 在工作流中的排序顺序
  "retry_count": "number",          // 重试次数
  "max_retry": "number",            // 最大重试次数
  "execution_context": "object"     // 执行上下文（包含项目ID、任务ID等）
}
```

#### 字段详细说明

##### 基础信息字段
- **id**: 数据库自增主键，用于关联查询
- **node_id**: 节点唯一标识符，在工作流中唯一，格式通常为 `node_{timestamp}_{random}`
- **tool_uuid**: 工具的固定UUID标识，对应具体的AI工具功能
- **tool_name**: 工具的可读名称，用于前端显示
- **step_index**: 在工作流中的执行顺序，从0开始

##### 状态管理字段
- **status**: 节点执行状态，用于跟踪执行进度和错误处理
- **retry_count/max_retry**: 重试机制相关，支持失败重试
- **start_time/end_time/duration_ms**: 执行时间跟踪，用于性能监控

##### 数据字段
- **input_data**: 节点输入参数，结构根据工具类型动态变化
- **output_data**: 节点输出结果，包含主要结果和元数据信息
- **execution_context**: 执行上下文，包含项目、任务等关联信息

##### 文件管理字段
- **original_files**: 第三方API返回的原始文件链接，可能是临时的
- **output_files**: 转换后存储在项目文件系统中的文件信息
- 每个文件对象包含完整的元数据，便于文件管理和访问控制

##### 工作流关系字段
- **workflow_id**: 标识节点所属的工作流
- **parent_node_id/child_node_ids**: 构建节点间的依赖关系
- **sort_order**: 确保节点按正确顺序执行

##### 用户关联字段
- **creator_id**: 标识创建该节点的用户
- **preview_required**: 控制是否需要向前端推送预览结果

#### 文件处理机制说明

**original_files 字段**：
- 存储第三方API或本地API返回的原始文件链接
- 格式：`["https://api.example.com/files/abc123.jpg", "https://local.api/temp/video456.mp4"]`
- 这些文件可能是临时链接，需要及时下载和转存

**output_files 字段**：
- 存储项目文件存储系统中的objectName
- 格式：`["image/2024/12/abc123_processed.jpg", "video/2024/12/video456_final.mp4"]`
- 这些是持久化存储的文件标识，可长期访问

**文件转换流程**：
1. 工具执行完成后，从`original_files`中获取原始文件链接
2. 系统自动下载这些文件到本地临时目录
3. 将文件上传到项目配置的文件存储系统（MinIO/OSS等）
4. 获得objectName后存储到`output_files`字段
5. 清理本地临时文件
6. 返回处理后的节点数据给前端

##### 1. 文生图节点
```json
{
  "tool_uuid": "tool-text2img-001",
  "tool_name": "文生图",
  "input_data": {
    "prompt": "string",             // 图片提示词
    "aspect_ratio": "string"         // 图片比例："1:1", "16:9", "9:16", "4:3"
  },
  "output_data": {
    "image_info": "object"          // 图片信息
  },
  "output_files": ["image_url"],
  "original_files": ["image_url"],
  "preview_required": true
}
```

##### 2. 图生图节点
```json
{
  "tool_uuid": "tool-img2img-002",
  "tool_name": "图生图",
  "input_data": {
    "prompt": "string",             // 图片提示词
    "source_image_url": "string",   // 源图片URL
    "aspect_ratio": "string"         // 图片比例："1:1", "16:9", "9:16", "4:3"
  },
  "output_data": {
    "image_info": "object"          // 图片信息
  },
  "output_files": ["image_url"],
  "original_files": ["image_url"],
  "preview_required": true
}
```

##### 3. 图生视频节点
```json
{
  "tool_uuid": "tool-img2video-003",
  "tool_name": "图生视频",
  "input_data": {
    "prompt": "string",             // 视频提示词
    "source_image_url": "string",   // 源图片URL（可选）
    "aspect_ratio": "string"         // 视频比例："16:9", "9:16", "1:1"
  },
  "output_data": {
    "video_info": "object"          // 视频信息
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

##### 4. 文生视频节点
```json
{
  "tool_uuid": "tool-text2video-004",
  "tool_name": "文生视频",
  "input_data": {
    "prompt": "string",             // 视频提示词
    "aspect_ratio": "string"         // 视频比例："16:9", "9:16", "1:1"
  },
  "output_data": {
    "video_info": "object"          // 视频信息
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```


##### 5. 背景音乐生成节点
```json
{
  "tool_uuid": "tool-music-gen-005",
  "tool_name": "背景音乐生成",
  "input_data": {
    "prompt": "string"              // 音乐描述
  },
  "output_data": {
    "music_info": "object"          // 音乐信息
  },
  "output_files": ["audio_url"],
  "original_files": ["audio_url"],
  "preview_required": true
}
```


##### 6. 文案转语音节点
```json
{
  "tool_uuid": "tool-text2speech-008",
  "tool_name": "文案转语音",
  "input_data": {
    "text": "string",               // 待转换文本
    "voice_id": "string",          // 声音ID
    "speed": "number",             // 语速 (0.5-2.0)
    "pitch": "number",             // 音调 (0.5-2.0)
    "volume": "number"             // 音量 (0.0-1.0)
  },
  "output_data": {
    "audio_info": "object",        // 音频信息
    "duration": "number"           // 音频时长(秒)
  },
  "output_files": ["audio_url"],
  "original_files": ["audio_url"],
  "preview_required": true
}
```

##### 7. 语音生成字幕节点
```json
{
  "tool_uuid": "tool-speech2sub-009",
  "tool_name": "语音生成字幕",
  "input_data": {
    "audio_url": "string",         // 音频文件URL
    "language": "string",          // 语言代码 (zh-CN, en-US等)
    "format": "string"             // 字幕格式 (srt, vtt, ass)
  },
  "output_data": {
    "subtitle_info": "object",     // 字幕信息
    "word_count": "number",        // 词数
    "segments": "array"            // 字幕片段
  },
  "output_files": ["subtitle_url"],
  "original_files": ["subtitle_url"],
  "preview_required": false
}
```

##### 8. 视频合并节点
```json
{
  "tool_uuid": "tool-video-merge-010",
  "tool_name": "视频合并",
  "input_data": {
    "video_urls": "array",         // 视频文件URL列表
    "transition_type": "string",   // 转场类型
    "transition_duration": "number" // 转场时长(秒)
  },
  "output_data": {
    "merged_video_info": "object", // 合并后视频信息
    "total_duration": "number"     // 总时长(秒)
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

##### 9. 音视频合并节点
```json
{
  "tool_uuid": "tool-av-merge-011",
  "tool_name": "音视频合并",
  "input_data": {
    "video_url": "string",         // 视频文件URL
    "audio_url": "string",         // 音频文件URL
    "audio_volume": "number",      // 音频音量 (0.0-1.0)
    "fade_in": "number",           // 淡入时长(秒)
    "fade_out": "number"           // 淡出时长(秒)
  },
  "output_data": {
    "merged_video_info": "object", // 合并后视频信息
    "total_duration": "number"     // 总时长(秒)
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

##### 10. 字幕视频合并节点
```json
{
  "tool_uuid": "tool-sub-merge-012",
  "tool_name": "字幕视频合并",
  "input_data": {
    "video_url": "string",         // 视频文件URL
    "subtitle_url": "string",      // 字幕文件URL
    "font_family": "string",       // 字体
    "font_size": "number",         // 字体大小
    "font_color": "string",        // 字体颜色
    "position": "string"           // 字幕位置: "bottom", "top", "center"
  },
  "output_data": {
    "final_video_info": "object",  // 最终视频信息
    "subtitle_embedded": "boolean" // 字幕是否成功嵌入
  },
  "output_files": ["video_url"],
  "original_files": ["video_url"],
  "preview_required": true
}
```

### 2. 任务执行页面重构

#### 2.1 页面布局需求
用户端前端项目的首页中有一个输入框，点击提交时会跳转到【任务中心页面】(`http://localhost:3000/ai-task`)。

**当前任务执行页面需要重构，参考设计截图**：

- **左侧面板**：显示历史项目列表
  - 支持项目搜索和分类
  - 点击项目可以加载并在右侧查看详细内容
  - 项目状态显示（进行中、已完成、失败等）

- **右侧面板**：对话框界面
  - 只支持一轮对话（用户输入 → AI执行 → 完成）
  - 用户可以输入任意要求
  - 实时显示工作流执行过程
  - 中间结果预览（图片、视频、音频）

#### 2.2 交互流程
1. **输入阶段**：用户输入提示词，可选择上传参考图片（0-6张）
   - **纯文字模式**：仅输入提示词，系统通过文生图→图生视频或直接文生视频
   - **图片辅助模式**：上传1-6张参考图片，结合提示词进行图生图→图生视频
   - **混合模式**：部分图片+文字描述，灵活组合生成内容
2. **分析阶段**：Python后端LLM分析提示词和上传内容，生成动态工作流
3. **执行阶段**：按顺序执行工作流节点，实时反馈进度
4. **预览阶段**：每个节点完成后，立即在对话框中预览结果
5. **完成阶段**：所有节点执行完成，生成最终视频

#### 2.3 实时反馈需求
提交提示词后，后端会按顺序输出中间结果，例如：
- 先生成图片 → 对话框预览图片
- 然后生成视频 → 对话框预览视频
- 创建背景音乐 → 对话框预览音频
- 创建广告口播 → 对话框预览音频和文案
- 最后合成视频 → 对话框预览最终视频

### 3. 项目任务创建流程

#### 3.1 项目创建
用户提交提示词后（可包含0-6张图片），后端创建一个空项目：
- 项目状态：初始状态
- 存储用户输入的提示词和上传的文件（如有）
- 分配唯一的项目ID
- 根据输入内容类型确定工作流模式

#### 3.2 工作流生成
LLM分析用户提示词和上传图片，一次性完成以下工作：
- **图片理解**：分析上传的图片，生成详细的文字描述
- **提示词生成**：基于用户需求和图片分析，生成优化的图片和视频提示词
- **工作流规划**：生成包含执行顺序的完整工作流JSON
- **参数预设**：为每个工具节点预设好所需的提示词和参数

生成的工作流包含：
- **有顺序的节点链**：定义执行顺序
- **预生成的提示词**：每个节点已包含LLM优化后的提示词
- **执行位置跟踪**：当前执行到哪个节点
- **文件管理**：每个节点生成的文件都需要上传到文件存储中，返回objectName保存到节点输出字段

#### 3.3 工作流示例

**场景1：图片辅助模式（有上传图片）**
```
图生图1->图生图2->图生图3->图生视频1->图生视频2->图生视频3->文案转语音->语音生成字幕->背景音乐生成->视频合并->音视频合并1->音视频合并2->字幕视频合并
```
*LLM预处理：分析上传图片 → 生成优化的图片提示词 → 生成视频提示词 → 生成口播文案*

**场景2：纯文字模式（无上传图片）**
```
文生图1->文生图2->文生图3->图生视频1->图生视频2->图生视频3->文案转语音->语音生成字幕->背景音乐生成->视频合并->音视频合并1->音视频合并2->字幕视频合并
```
*LLM预处理：分析用户需求 → 生成图片提示词 → 生成视频提示词 → 生成口播文案*

**场景3：直接文生视频模式**
```
文生视频1->文生视频2->文生视频3->文案转语音->语音生成字幕->背景音乐生成->视频合并->音视频合并1->音视频合并2->字幕视频合并
```
*LLM预处理：分析用户需求 → 直接生成视频提示词 → 生成口播文案*

### 4. 项目任务执行流程

#### 4.1 执行逻辑
1. **LLM预处理阶段**：Java后端调用Python后端，LLM分析用户提示词和上传图片，一次性完成图片理解、提示词生成和工作流规划
2. **工具执行阶段**：按照生成的工作流顺序执行各个AI工具，所有提示词已预先优化生成

#### 4.2 执行示例
以香氛产品视频为例：

**LLM预处理阶段**：
- 分析用户输入："为香氛产品制作优雅广告视频"
- 理解上传的3张图片：女性、产品、场景
- 生成优化的图片提示词："elegant woman with luxury perfume bottle, soft lighting, commercial style"
- 生成优化的视频提示词："cinematic slow motion perfume commercial, elegant movement, luxury aesthetic"

**工具执行阶段**：
1. **图生图1**：上传图片1 + 预生成提示词1 → 优化图片1
2. **图生图2**：上传图片2 + 预生成提示词2 → 优化图片2
3. **图生图3**：上传图片3 + 预生成提示词3 → 优化图片3
4. **图生视频1**：优化图片1 + 预生成视频提示词1 → 视频片段1
5. **图生视频2**：优化图片2 + 预生成视频提示词2 → 视频片段2
6. **图生视频3**：优化图片3 + 预生成视频提示词3 → 视频片段3
7. **文案转语音**：预生成广告文案 → 语音文件
8. **语音生成字幕**：语音文件 → 字幕文件
9. **背景音乐生成**：根据风格生成 → 背景音乐
10. **视频合并**：视频片段1+2+3 → 主视频
11. **音视频合并1**：主视频+背景音乐 → 带音乐视频
12. **音视频合并2**：带音乐视频+语音 → 完整音频视频
13. **字幕视频合并**：完整音频视频+字幕 → 最终广告视频

#### 4.3 动态工作流
根据用户不同的描述，会动态地规划整体流程。每个阶段输出的文件都需要反馈到前端对话框中显示预览。

### 5. 文件上传和转换服务设计

#### 5.1 服务架构

**Java后端文件转换服务**：
```java
@Service
public class FileConversionService {

    @Autowired
    private OssService ossService;

    /**
     * 将original_files转换为output_files
     */
    public List<String> convertFilesToStorage(List<String> originalFiles, String nodeId);

    /**
     * 下载原始文件到临时目录
     */
    private File downloadFile(String originalUrl, String fileName);

    /**
     * 上传文件到存储系统
     */
    private String uploadToStorage(File file, String category);

    /**
     * 清理临时文件
     */
    private void cleanupTempFiles(List<File> tempFiles);
}
```

#### 5.2 转换流程

**步骤1：原始文件下载**
- 从original_files数组中获取所有原始文件链接
- 并发下载文件到临时目录：`/tmp/tool-files/{nodeId}/`
- 根据文件扩展名确定文件类型（image/video/audio）
- 下载失败时记录错误并跳过该文件

**步骤2：文件上传存储**
- 根据文件类型和当前日期生成存储路径：`{type}/{year}/{month}/{filename}`
- 调用OSS服务上传文件
- 获得objectName并添加到output_files数组
- 记录上传结果和耗时

**步骤3：临时文件清理**
- 上传成功后立即删除本地临时文件
- 定期清理超时的临时文件（1小时后自动清理）
- 异常情况下确保临时文件不会堆积

#### 5.3 异常处理

**下载失败处理**：
- 记录失败的原始链接和错误原因
- 设置重试机制（最多3次）
- 部分文件失败不影响其他文件处理
- 在节点error_message中记录失败详情

**上传失败处理**：
- 记录上传失败的文件和错误原因
- 保留已成功上传的文件objectName
- 设置重试机制
- 通知前端部分文件处理失败

#### 5.4 配置参数

```yaml
file.conversion:
  temp-dir: /tmp/tool-files/
  download-timeout: 30s
  upload-timeout: 60s
  max-file-size: 100MB
  retry-times: 3
  cleanup-interval: 1h
  supported-formats:
    image: [jpg, jpeg, png, gif, webp]
    video: [mp4, avi, mov, mkv]
    audio: [mp3, wav, aac, flac]
```

### 6. LLM预处理服务设计

#### 6.1 预处理流程

**输入**：
- 用户提示词：文字描述需求
- 上传图片：0-6张参考图片（可选）

**LLM处理步骤**：
1. **需求分析**：理解用户意图、风格要求、输出规格等
2. **图片理解**：调用视觉模型分析上传的图片，生成详细描述
3. **提示词优化**：基于需求和图片分析，生成专业的AI提示词
4. **工作流规划**：确定执行路径和工具序列
5. **参数预设**：为每个工具节点预设优化的参数

**输出**：
- 完整的工作流JSON，包含所有节点的预设提示词
- 图片分析结果（用于项目记录）
- 执行策略说明

#### 6.2 提示词生成策略

**图片提示词生成**：
```python
def generate_image_prompt(user_input, image_analysis):
    # 结合用户需求和图片特征
    # 添加专业摄影术语
    # 优化艺术风格描述
    # 确保AI生成质量
    return optimized_prompt
```

**视频提示词生成**：
```python
def generate_video_prompt(user_input, image_prompt=None):
    # 添加镜头运动描述
    # 指定时长和帧率
    # 优化动作和转场
    # 确保视频连贯性
    return optimized_prompt
```

#### 6.3 工作流智能规划

根据输入内容智能选择执行路径：
- **有图片输入**：图生图 → 图生视频路径
- **纯文字输入**：文生图 → 图生视频路径
- **视频导向**：直接文生视频路径
- **复杂需求**：多路径并行执行

### 7. 关键技术难点

#### 5.1 动态工作流参数传递
**问题**：如何保证动态生成的工作流（工具链）能够正常执行衔接，不至于入参混乱错误？

**解决方案**：
- 使用JSON Schema定义工具输入输出格式
- LLM生成工作流时包含详细的参数映射规则
- 运行时动态解析和验证参数
- 工具调用前进行参数类型检查和转换

#### 5.2 任务中断恢复
**问题**：如何能够在工作流运行中突然宕机然后重启后能够继续恢复任务？

**解决方案**：
- 每个节点执行后立即保存状态到数据库
- 记录当前执行位置和中间结果
- 重启时从最后成功节点继续执行
- 文件引用使用objectName确保持久化

#### 5.3 文件自动管理
**问题**：如何能够自动下载需要的文件数据以及自动上传输出的文件数据？

**解决方案**：
- 节点执行前自动从文件存储下载所需文件
- 节点完成后自动上传输出文件到文件存储
- 临时文件目录管理和清理
- 文件URL生成和访问权限控制

#### 5.4 预览结果控制
**问题**：如何设置工具链中，哪些工具的结果需要返回前端并预览，哪些工具结果不做预览直接下一步？

**解决方案**：
- 工具定义中包含`preview_required`字段
- 重要的中间结果（图片、视频、音频）需要预览
- 纯文本处理结果可以不预览
- 支持配置化的预览策略

#### 5.5 实时状态推送
**问题**：如何在工作流运行中动态返回生成的结果并实时交互通知前端显示流程中间结果？

**解决方案**：
- 使用WebSocket建立实时连接
- 节点开始/完成时推送状态更新
- 包含中间结果文件URL供前端下载预览
- 错误信息实时反馈和用户提示

## 数据库设计

### 1. AI项目表 (ai_project)
```sql
CREATE TABLE ai_project (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    prompt TEXT NOT NULL,           -- 用户输入的提示词
    uploaded_files JSON,            -- 上传的文件列表
    status INT DEFAULT 0,           -- 0:创建中 1:执行中 2:已完成 3:失败
    member_id BIGINT NOT NULL,      -- 所属用户ID
    create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

### 2. AI任务表 (ai_task)
```sql
CREATE TABLE ai_task (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    project_id BIGINT NOT NULL,
    task_type VARCHAR(100) NOT NULL,
    status INT DEFAULT 0,           -- 0:待执行 1:执行中 2:已完成 3:失败
    workflow_json TEXT,             -- 工作流定义JSON
    current_step INT DEFAULT 0,     -- 当前执行步骤
    total_steps INT DEFAULT 0,      -- 总步骤数
    python_task_id VARCHAR(100),    -- Python后端任务ID
    result_files JSON,              -- 最终结果文件列表
    create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

### 3. 工作流执行记录表 (ai_workflow_execution)
```sql
CREATE TABLE ai_workflow_execution (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    task_id BIGINT NOT NULL,
    node_id VARCHAR(100) NOT NULL,      -- 节点唯一ID
    tool_uuid VARCHAR(100) NOT NULL,    -- 工具UUID
    tool_name VARCHAR(100) NOT NULL,    -- 工具名称
    step_index INT NOT NULL,            -- 步骤索引
    status INT DEFAULT 0,               -- 0:待执行 1:执行中 2:已完成 3:失败
    input_data TEXT,                    -- 输入数据JSON
    output_data TEXT,                   -- 输出数据JSON
    output_files JSON,                  -- 输出文件列表（项目存储objectName）
    original_files JSON,                -- 原始文件列表（第三方API返回链接）
    preview_required BOOLEAN DEFAULT FALSE, -- 是否需要前端预览
    error_message TEXT,                 -- 错误信息
    start_time DATETIME,
    end_time DATETIME,
    duration_ms INT,                    -- 执行耗时(毫秒)
    creator_id BIGINT,                  -- 创建者ID
    workflow_id VARCHAR(100),           -- 工作流ID
    parent_node_id VARCHAR(100),        -- 父节点ID
    sort_order INT                      -- 节点排序
);
```

### 4. AI工具注册表 (ai_tool)
```sql
CREATE TABLE ai_tool (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    tool_uuid VARCHAR(100) UNIQUE NOT NULL,  -- 工具UUID
    tool_name VARCHAR(100) NOT NULL,         -- 工具名称
    tool_description TEXT,                   -- 工具描述
    tool_type VARCHAR(50) NOT NULL,          -- 工具类型(image,video,audio,text)
    input_schema JSON,                       -- 输入参数Schema
    output_schema JSON,                      -- 输出参数Schema
    preview_required BOOLEAN DEFAULT FALSE,  -- 是否需要前端预览
    is_local BOOLEAN DEFAULT FALSE,          -- 是否本地工具
    api_endpoint VARCHAR(255),               -- API端点
    status INT DEFAULT 1,                    -- 工具状态 0:禁用 1:启用
    create_time DATETIME DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

### 7. 实现示例

#### 7.1 文件转换服务实现

```java
@Service
@Slf4j
public class FileConversionServiceImpl implements FileConversionService {

    @Autowired
    private OssService ossService;

    @Value("${file.conversion.temp-dir:/tmp/tool-files/}")
    private String tempDir;

    @Value("${file.conversion.retry-times:3}")
    private int retryTimes;

    @Override
    public List<String> convertFilesToStorage(List<String> originalFiles, String nodeId) {
        if (CollectionUtils.isEmpty(originalFiles)) {
            return new ArrayList<>();
        }

        List<String> outputFiles = new ArrayList<>();
        List<File> tempFiles = new ArrayList<>();

        try {
            // 创建临时目录
            String nodeTempDir = tempDir + "/" + nodeId;
            FileUtils.forceMkdir(new File(nodeTempDir));

            // 并发下载原始文件
            List<CompletableFuture<DownloadResult>> downloadFutures = originalFiles.stream()
                .map(url -> CompletableFuture.supplyAsync(() -> downloadWithRetry(url, nodeTempDir)))
                .collect(Collectors.toList());

            // 等待所有下载完成
            CompletableFuture.allOf(downloadFutures.toArray(new CompletableFuture[0])).join();

            // 处理下载结果
            for (CompletableFuture<DownloadResult> future : downloadFutures) {
                DownloadResult result = future.get();
                if (result.isSuccess()) {
                    tempFiles.add(result.getFile());

                    // 上传到存储系统
                    String objectName = uploadWithRetry(result.getFile());
                    if (objectName != null) {
                        outputFiles.add(objectName);
                    }
                } else {
                    log.error("文件下载失败: {}, 错误: {}", result.getOriginalUrl(), result.getError());
                }
            }

        } catch (Exception e) {
            log.error("文件转换服务异常", e);
        } finally {
            // 清理临时文件
            cleanupTempFiles(tempFiles);
        }

        return outputFiles;
    }

    private DownloadResult downloadWithRetry(String originalUrl, String tempDir) {
        for (int i = 0; i < retryTimes; i++) {
            try {
                File file = downloadFile(originalUrl, tempDir);
                return DownloadResult.success(file, originalUrl);
            } catch (Exception e) {
                log.warn("第{}次下载失败: {}, 错误: {}", i + 1, originalUrl, e.getMessage());
                if (i == retryTimes - 1) {
                    return DownloadResult.failure(originalUrl, e.getMessage());
                }
                // 等待后重试
                try {
                    Thread.sleep(1000 * (i + 1));
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        }
        return DownloadResult.failure(originalUrl, "重试次数耗尽");
    }

    private String uploadWithRetry(File file) {
        for (int i = 0; i < retryTimes; i++) {
            try {
                return uploadToStorage(file);
            } catch (Exception e) {
                log.warn("第{}次上传失败: {}, 错误: {}", i + 1, file.getName(), e.getMessage());
                if (i < retryTimes - 1) {
                    try {
                        Thread.sleep(1000 * (i + 1));
                    } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                        break;
                    }
                }
            }
        }
        return null;
    }
}
```

#### 7.2 工具节点处理流程

```java
@Service
public class ToolNodeProcessor {

    @Autowired
    private FileConversionService fileConversionService;

    /**
     * 处理工具节点执行结果
     */
    public void processToolNodeResult(ToolNodeResult nodeResult) {
        try {
            // 1. 更新节点状态为执行中
            updateNodeStatus(nodeResult.getNodeId(), NodeStatus.PROCESSING);

            // 2. 处理original_files转换为output_files
            if (CollectionUtils.isNotEmpty(nodeResult.getOriginalFiles())) {
                List<String> outputFiles = fileConversionService.convertFilesToStorage(
                    nodeResult.getOriginalFiles(),
                    nodeResult.getNodeId()
                );
                nodeResult.setOutputFiles(outputFiles);
            }

            // 3. 保存节点执行结果
            saveNodeResult(nodeResult);

            // 4. 更新节点状态为完成
            updateNodeStatus(nodeResult.getNodeId(), NodeStatus.COMPLETED);

            // 5. 如果需要预览，推送结果到前端
            if (nodeResult.isPreviewRequired()) {
                pushResultToFrontend(nodeResult);
            }

        } catch (Exception e) {
            log.error("处理工具节点结果失败: {}", nodeResult.getNodeId(), e);
            updateNodeStatus(nodeResult.getNodeId(), NodeStatus.FAILED);
            updateNodeError(nodeResult.getNodeId(), e.getMessage());
        }
    }
}
```

## API接口设计

### Java后端新增API

#### 1. 项目管理API
```java
@RestController
@RequestMapping("/api/ai/project")
public class AIProjectController {

    @PostMapping("/create")
    CommonResult<AIProject> createProject(@RequestBody CreateProjectParam param);

    @GetMapping("/list")
    CommonResult<List<AIProjectListResult>> getProjectList(@RequestParam Long memberId);

    @GetMapping("/{id}")
    CommonResult<AIProjectDetailResult> getProjectDetail(@PathVariable Long id);

    @DeleteMapping("/{id}")
    CommonResult<Void> deleteProject(@PathVariable Long id);
}
```

#### 2. AI任务API
```java
@RestController
@RequestMapping("/api/ai/task")
public class AITaskController {

    @PostMapping("/submit")
    CommonResult<AITask> submitTask(@RequestBody SubmitTaskParam param);

    @GetMapping("/{taskId}/status")
    CommonResult<TaskStatusResult> getTaskStatus(@PathVariable Long taskId);

    @GetMapping("/{taskId}/workflow")
    CommonResult<WorkflowStatusResult> getWorkflowStatus(@PathVariable Long taskId);

    @PostMapping("/{taskId}/stop")
    CommonResult<Void> stopTask(@PathVariable Long taskId);
}
```

### Python FastAPI接口

#### 1. 工作流API
```python
@router.post("/workflow/generate")
async def generate_workflow(request: WorkflowGenerateRequest) -> WorkflowResponse:
    """根据提示词生成工作流"""
    pass

@router.post("/workflow/execute")
async def execute_workflow(request: WorkflowExecuteRequest) -> TaskResponse:
    """执行工作流"""
    pass

@router.get("/workflow/{task_id}/status")
async def get_workflow_status(task_id: str) -> WorkflowStatusResponse:
    """获取工作流执行状态"""
    pass
```

#### 2. AI工具API
```python
@router.get("/tools/list")
async def list_tools() -> ToolListResponse:
    """获取可用工具列表"""
    pass

@router.post("/tools/{tool_uuid}/execute")
async def execute_tool(tool_uuid: str, request: ToolExecuteRequest) -> ToolResponse:
    """执行指定工具"""
    pass
```

## 实施优先级

### Phase 1: 基础架构 (3-4天)
1. 创建Python FastAPI项目基础结构
2. 数据库表设计和创建
3. Java后端API框架搭建
4. 基础的项目CRUD功能
5. **AI模型适配器架构实现**
   - 定义BaseAIAdapter抽象基类
   - 实现AIAdapterFactory工厂类
   - 配置管理系统设计
   - 适配器注册和发现机制

### Phase 2: 混合平台AI工具集成 (5-6天)

#### 第一阶段：核心架构实现 (Day 1-2)
1. **智能适配器选择器实现**
   - SmartAdapterSelector核心逻辑
   - 混合平台配置管理系统
   - 降级策略和健康检查机制
   - 性能监控和使用统计

2. **豆包适配器完善**
   - 基于异步任务模式的核心架构（✅ 已有图生视频）
   - 完善其余API接口实现
   - 统一的HTTP请求封装和错误处理

#### 第二阶段：多平台适配器实现 (Day 3-4)
1. **通义千问适配器** - 专精图像生成
   - TongYiAdapter基础实现
   - text_to_image优质实现（主力）
   - image_to_image优质实现（主力）
   - 其他接口基础实现（备用）

2. **文心一言适配器** - 专精音频处理
   - WenXinAdapter基础实现
   - generate_music优质实现（主力）
   - text_to_speech优质实现（主力）
   - 其他接口基础实现（备用）

3. **豆包适配器补全** - 专精视频生成
   - image_to_video优质实现（✅ 已完成）
   - text_to_video优质实现（✅ 已完成）
   - speech_to_subtitle优质实现（主力）
   - 文生图、图生图基础实现（备用）

#### 第三阶段：混合平台集成测试 (Day 5-6)
1. **混合工作流测试**
   - 图像生成（通义）→ 视频生成（豆包）→ 音频处理（文心）
   - 故障转移测试：主平台挂掉后自动切换备用平台
   - 成本优化测试：根据配置选择最经济的平台组合

2. **平台性能对比**
   - 各平台在不同任务上的质量对比
   - 成本效益分析和优化建议
   - 响应时间和稳定性测试

3. **配置管理和监控**
   - 热配置更新功能
   - 平台使用统计和分析
   - 告警和故障恢复机制

**Phase 2 的关键交付物：**
- ✅ 智能适配器选择系统
- ✅ 三大平台适配器（豆包、通义、文心）
- ✅ 混合平台配置管理
- ✅ 故障转移和性能监控
- ✅ 完整的混合工作流测试报告

**平台能力分工：**
```
📸 图像任务  → 通义千问（主）+ 豆包（备）+ 文心（备）
🎬 视频任务  → 豆包（主）+ 通义（备）+ 文心（备）
🎵 音频任务  → 文心（主）+ 豆包（备）+ 通义（备）
```

### Phase 3: 工作流引擎 (4-5天)
1. LLM工作流生成逻辑
2. 工作流执行引擎
3. 状态管理和中断恢复
4. 参数传递和验证

### Phase 4: 前端重构 (3-4天)
1. 任务执行页面UI重构
2. WebSocket实时通信集成
3. 中间结果预览功能
4. 用户体验优化

### Phase 5: 集成测试 (2-3天)
1. 端到端流程测试
2. 错误处理测试
3. 性能优化
4. 生产环境部署

## 成功标准

### 基础功能标准
1. **功能完整性**：用户可以输入提示词和图片，系统自动生成完整视频
2. **实时反馈**：工作流执行过程中，前端能实时显示进度和中间结果
3. **稳定性**：系统在异常情况下能够恢复和继续执行
4. **性能**：单个任务处理时间在合理范围内（10-30分钟）
5. **用户体验**：界面友好，操作简单，错误提示清晰

### 混合平台集成标准
6. **平台智能选择**：系统能根据任务类型自动选择最佳AI平台
   - 文生图自动选择通义千问
   - 图生视频自动选择豆包
   - 音频处理自动选择文心一言
7. **故障自动转移**：主平台不可用时，自动切换到备用平台，成功率≥95%
8. **成本优化**：在保证质量前提下，平均成本比单一平台降低20-30%
9. **配置热更新**：支持不重启服务的平台配置更新
10. **性能监控**：实时监控各平台使用情况、成功率、响应时间

## 风险和挑战

1. **AI服务稳定性**：第三方AI API的可用性和响应时间
2. **文件处理性能**：大视频文件的上传下载和处理效率
3. **工作流复杂度**：动态生成的工作流可能过于复杂难以执行
4. **成本控制**：AI API调用费用的控制和优化
5. **并发处理**：多用户同时使用时的资源分配和性能保证

## 后续扩展

### 基础功能扩展
1. **模板库**：预定义常用的工作流模板
2. **批量处理**：支持批量上传和批量生成
3. **社区功能**：用户分享作品和模板
4. **API开放**：为第三方开发者提供API接口
5. **移动端支持**：开发移动端应用

### 混合平台扩展
6. **更多AI平台接入**：
   - 国际平台：OpenAI GPT-4, Claude, Midjourney, Runway
   - 国内平台：智谱AI, 百川智能, MiniMax
   - 开源模型：Stable Diffusion, LLaMA等本地部署
7. **智能成本控制**：
   - AI预算管理和用量限制
   - 实时成本监控和告警
   - 成本优化建议引擎
8. **平台性能优化**：
   - 负载均衡和并发控制
   - 缓存机制减少重复调用
   - 预测性故障检测
9. **企业级功能**：
   - 多租户平台配置隔离
   - 精细化权限控制
   - 审计日志和合规性支持

### 技术创新扩展
10. **AI模型自动评估**：根据任务结果自动调整平台选择策略
11. **混合推理**：同时调用多个平台对比结果，选择最佳输出
12. **边缘计算集成**：本地模型 + 云端模型混合部署